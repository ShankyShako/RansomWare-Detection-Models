{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvSStDNagxYQ",
        "outputId": "0fbc5bbb-7297-4767-fba7-d421e7aab4df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Reading the csv file\n",
        "df = pd.read_csv('/content/drive/MyDrive/RansomwareData.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8eU_XsxgzKL"
      },
      "outputs": [],
      "source": [
        "X = df.drop(df.columns[0], axis=1)\n",
        "X = X.drop(df.columns[1], axis=1)\n",
        "X = X.drop(df.columns[2], axis=1)\n",
        "y = df[df.columns[2]]\n",
        "\n",
        "y_binary = df[df.columns[1]]\n",
        "# Create group labels\n",
        "def convert_to_group(label):\n",
        "    if label in [2, 3, 8, 10]:  # Traditional File Encryptors\n",
        "        return 1\n",
        "    elif label in [6, 9]:  # Locker Ransomware\n",
        "        return 2\n",
        "    elif label in [5, 7]:  # Ransomware with Trojan-like Behavior\n",
        "        return 3\n",
        "    elif label == 1:  # Hybrid and Multifaceted Ransomware\n",
        "        return 4\n",
        "    elif label in [4, 11]:  # Specialty Ransomware\n",
        "        return 5\n",
        "    else:\n",
        "        return 0  # Assuming 0 is for goodware or an undefined class\n",
        "\n",
        "# Apply the grouping function to the multi-class labels\n",
        "y_group = y.apply(convert_to_group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCMRmuq3g3sv",
        "outputId": "7c2c0b69-ba30-40cc-ac98-c31d6f0c43a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assume df is your DataFrame and contains your data\n",
        "X = df.drop([df.columns[0], df.columns[1], df.columns[2]], axis=1).values\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Fit K-means with the desired number of clusters\n",
        "kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "cluster_labels = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# One-hot encode cluster labels if desired\n",
        "cluster_labels_one_hot = tf.keras.utils.to_categorical(cluster_labels)\n",
        "\n",
        "# Concatenate the cluster labels with the original features\n",
        "X_w_clusters = np.hstack((X, cluster_labels_one_hot))\n",
        "\n",
        "# Update the input shape\n",
        "input_shape_with_clusters = X_w_clusters.shape[1]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_with_clusters, X_test_with_clusters, y_train, y_test, y_train_binary, y_test_binary, y_train_group, y_test_group = train_test_split(X_w_clusters, y, y_binary, y_group, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qa3JGK5PgnXp",
        "outputId": "9c1d1f64-497a-4796-fe68-afd1088acbd0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30971</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30970</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15485</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15484</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7742</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7742</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">330,240</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)        │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">990976</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_block[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">253,690,112</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ binary_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ group_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ specific_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">780</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30971\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30970\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │            \u001b[38;5;34m768\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15485\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15484\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │         \u001b[38;5;34m65,664\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7742\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7742\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m330,240\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)        │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m990976\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ transformer_block[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m253,690,112\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m25,700\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m6,464\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ binary_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ group_output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m390\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ specific_output (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │            \u001b[38;5;34m780\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">254,120,183</span> (969.39 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m254,120,183\u001b[0m (969.39 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">254,120,183</span> (969.39 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m254,120,183\u001b[0m (969.39 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:664: UserWarning: Gradients do not exist for variables ['kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3425s\u001b[0m 11s/step - binary_output_accuracy: 0.5568 - binary_output_custom_f1: 0.2501 - binary_output_precision: 0.4252 - binary_output_recall: 0.4365 - loss: 291.0558 - specific_output_categorical_accuracy: 0.4020 - specific_output_custom_f1: 0.3920 - specific_output_custom_precision: 0.3925 - specific_output_custom_recall: 0.3917 - val_binary_output_accuracy: 0.3836 - val_binary_output_custom_f1: 0.4985 - val_binary_output_precision: 0.3836 - val_binary_output_recall: 1.0000 - val_loss: 15.1374 - val_specific_output_categorical_accuracy: 0.0361 - val_specific_output_custom_f1: 0.0357 - val_specific_output_custom_precision: 0.0357 - val_specific_output_custom_recall: 0.0357\n",
            "Epoch 2/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3448s\u001b[0m 11s/step - binary_output_accuracy: 0.7357 - binary_output_custom_f1: 0.4333 - binary_output_precision: 0.6543 - binary_output_recall: 0.6119 - loss: 5.3607 - specific_output_categorical_accuracy: 0.5364 - specific_output_custom_f1: 0.5441 - specific_output_custom_precision: 0.5748 - specific_output_custom_recall: 0.5257 - val_binary_output_accuracy: 0.6623 - val_binary_output_custom_f1: 0.1143 - val_binary_output_precision: 1.0000 - val_binary_output_recall: 0.1197 - val_loss: 3.4172 - val_specific_output_categorical_accuracy: 0.7049 - val_specific_output_custom_f1: 0.7083 - val_specific_output_custom_precision: 0.7132 - val_specific_output_custom_recall: 0.7045\n",
            "Epoch 3/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3428s\u001b[0m 11s/step - binary_output_accuracy: 0.8048 - binary_output_custom_f1: 0.5869 - binary_output_precision: 0.7413 - binary_output_recall: 0.7439 - loss: 2.9830 - specific_output_categorical_accuracy: 0.6098 - specific_output_custom_f1: 0.6172 - specific_output_custom_precision: 0.6726 - specific_output_custom_recall: 0.5860 - val_binary_output_accuracy: 0.8787 - val_binary_output_custom_f1: 0.7409 - val_binary_output_precision: 0.7632 - val_binary_output_recall: 0.9915 - val_loss: 2.4828 - val_specific_output_categorical_accuracy: 0.5115 - val_specific_output_custom_f1: 0.5271 - val_specific_output_custom_precision: 0.5974 - val_specific_output_custom_recall: 0.4870\n",
            "Epoch 4/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3428s\u001b[0m 11s/step - binary_output_accuracy: 0.8546 - binary_output_custom_f1: 0.6788 - binary_output_precision: 0.7902 - binary_output_recall: 0.8625 - loss: 1.8504 - specific_output_categorical_accuracy: 0.6250 - specific_output_custom_f1: 0.6487 - specific_output_custom_precision: 0.7687 - specific_output_custom_recall: 0.5871 - val_binary_output_accuracy: 0.8820 - val_binary_output_custom_f1: 0.7262 - val_binary_output_precision: 0.7793 - val_binary_output_recall: 0.9658 - val_loss: 1.4017 - val_specific_output_categorical_accuracy: 0.6951 - val_specific_output_custom_f1: 0.7095 - val_specific_output_custom_precision: 0.9340 - val_specific_output_custom_recall: 0.6136\n",
            "Epoch 5/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3516s\u001b[0m 12s/step - binary_output_accuracy: 0.8676 - binary_output_custom_f1: 0.6827 - binary_output_precision: 0.8123 - binary_output_recall: 0.8724 - loss: 1.7969 - specific_output_categorical_accuracy: 0.6477 - specific_output_custom_f1: 0.6438 - specific_output_custom_precision: 0.7954 - specific_output_custom_recall: 0.5693 - val_binary_output_accuracy: 0.8787 - val_binary_output_custom_f1: 0.7409 - val_binary_output_precision: 0.7632 - val_binary_output_recall: 0.9915 - val_loss: 1.3982 - val_specific_output_categorical_accuracy: 0.6984 - val_specific_output_custom_f1: 0.6833 - val_specific_output_custom_precision: 0.8636 - val_specific_output_custom_recall: 0.5909\n",
            "Epoch 6/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3638s\u001b[0m 12s/step - binary_output_accuracy: 0.8995 - binary_output_custom_f1: 0.7239 - binary_output_precision: 0.8497 - binary_output_recall: 0.8936 - loss: 1.4075 - specific_output_categorical_accuracy: 0.6561 - specific_output_custom_f1: 0.6925 - specific_output_custom_precision: 0.8789 - specific_output_custom_recall: 0.6025 - val_binary_output_accuracy: 0.8492 - val_binary_output_custom_f1: 0.7224 - val_binary_output_precision: 0.7205 - val_binary_output_recall: 0.9915 - val_loss: 1.7897 - val_specific_output_categorical_accuracy: 0.5770 - val_specific_output_custom_f1: 0.6304 - val_specific_output_custom_precision: 0.8030 - val_specific_output_custom_recall: 0.5455\n",
            "Epoch 7/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4011s\u001b[0m 13s/step - binary_output_accuracy: 0.9063 - binary_output_custom_f1: 0.7512 - binary_output_precision: 0.8633 - binary_output_recall: 0.8964 - loss: 1.3963 - specific_output_categorical_accuracy: 0.6700 - specific_output_custom_f1: 0.6916 - specific_output_custom_precision: 0.8519 - specific_output_custom_recall: 0.6120 - val_binary_output_accuracy: 0.9475 - val_binary_output_custom_f1: 0.7524 - val_binary_output_precision: 0.9720 - val_binary_output_recall: 0.8889 - val_loss: 1.1493 - val_specific_output_categorical_accuracy: 0.7180 - val_specific_output_custom_f1: 0.7449 - val_specific_output_custom_precision: 0.9405 - val_specific_output_custom_recall: 0.6494\n",
            "Epoch 8/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4223s\u001b[0m 14s/step - binary_output_accuracy: 0.9075 - binary_output_custom_f1: 0.7582 - binary_output_precision: 0.8812 - binary_output_recall: 0.8909 - loss: 1.1798 - specific_output_categorical_accuracy: 0.6929 - specific_output_custom_f1: 0.6995 - specific_output_custom_precision: 0.8865 - specific_output_custom_recall: 0.6022 - val_binary_output_accuracy: 0.8656 - val_binary_output_custom_f1: 0.6346 - val_binary_output_precision: 0.9043 - val_binary_output_recall: 0.7265 - val_loss: 2.2116 - val_specific_output_categorical_accuracy: 0.6492 - val_specific_output_custom_f1: 0.6311 - val_specific_output_custom_precision: 0.8106 - val_specific_output_custom_recall: 0.5455\n",
            "Epoch 9/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4205s\u001b[0m 14s/step - binary_output_accuracy: 0.5363 - binary_output_custom_f1: 0.4652 - binary_output_precision: 0.4739 - binary_output_recall: 0.7724 - loss: 2.7588 - specific_output_categorical_accuracy: 0.5745 - specific_output_custom_f1: 0.2748 - specific_output_custom_precision: 0.3432 - specific_output_custom_recall: 0.2460 - val_binary_output_accuracy: 0.6164 - val_binary_output_custom_f1: 0.0000e+00 - val_binary_output_precision: 0.0000e+00 - val_binary_output_recall: 0.0000e+00 - val_loss: 2.1900 - val_specific_output_categorical_accuracy: 0.6164 - val_specific_output_custom_f1: 0.6201 - val_specific_output_custom_precision: 0.6201 - val_specific_output_custom_recall: 0.6201\n",
            "Epoch 10/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3954s\u001b[0m 13s/step - binary_output_accuracy: 0.6290 - binary_output_custom_f1: 0.0000e+00 - binary_output_precision: 0.0000e+00 - binary_output_recall: 0.0000e+00 - loss: 2.1309 - specific_output_categorical_accuracy: 0.6290 - specific_output_custom_f1: 0.6290 - specific_output_custom_precision: 0.6290 - specific_output_custom_recall: 0.6290 - val_binary_output_accuracy: 0.6164 - val_binary_output_custom_f1: 0.0000e+00 - val_binary_output_precision: 0.0000e+00 - val_binary_output_recall: 0.0000e+00 - val_loss: 2.1768 - val_specific_output_categorical_accuracy: 0.6164 - val_specific_output_custom_f1: 0.6201 - val_specific_output_custom_precision: 0.6201 - val_specific_output_custom_recall: 0.6201\n",
            "Epoch 11/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3506s\u001b[0m 11s/step - binary_output_accuracy: 0.5956 - binary_output_custom_f1: 0.0000e+00 - binary_output_precision: 0.0000e+00 - binary_output_recall: 0.0000e+00 - loss: 2.2248 - specific_output_categorical_accuracy: 0.5956 - specific_output_custom_f1: 0.5956 - specific_output_custom_precision: 0.5956 - specific_output_custom_recall: 0.5956 - val_binary_output_accuracy: 0.6164 - val_binary_output_custom_f1: 0.0000e+00 - val_binary_output_precision: 0.0000e+00 - val_binary_output_recall: 0.0000e+00 - val_loss: 2.1752 - val_specific_output_categorical_accuracy: 0.6164 - val_specific_output_custom_f1: 0.6201 - val_specific_output_custom_precision: 0.6201 - val_specific_output_custom_recall: 0.6201\n",
            "Epoch 12/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3526s\u001b[0m 12s/step - binary_output_accuracy: 0.6204 - binary_output_custom_f1: 0.0000e+00 - binary_output_precision: 0.0000e+00 - binary_output_recall: 0.0000e+00 - loss: 2.1575 - specific_output_categorical_accuracy: 0.6204 - specific_output_custom_f1: 0.6204 - specific_output_custom_precision: 0.6204 - specific_output_custom_recall: 0.6204 - val_binary_output_accuracy: 0.6164 - val_binary_output_custom_f1: 0.0000e+00 - val_binary_output_precision: 0.0000e+00 - val_binary_output_recall: 0.0000e+00 - val_loss: 2.1774 - val_specific_output_categorical_accuracy: 0.6164 - val_specific_output_custom_f1: 0.6201 - val_specific_output_custom_precision: 0.6201 - val_specific_output_custom_recall: 0.6201\n",
            "Epoch 13/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3544s\u001b[0m 12s/step - binary_output_accuracy: 0.6341 - binary_output_custom_f1: 0.0000e+00 - binary_output_precision: 0.0000e+00 - binary_output_recall: 0.0000e+00 - loss: 2.1095 - specific_output_categorical_accuracy: 0.6341 - specific_output_custom_f1: 0.6341 - specific_output_custom_precision: 0.6341 - specific_output_custom_recall: 0.6341 - val_binary_output_accuracy: 0.6164 - val_binary_output_custom_f1: 0.0000e+00 - val_binary_output_precision: 0.0000e+00 - val_binary_output_recall: 0.0000e+00 - val_loss: 2.1759 - val_specific_output_categorical_accuracy: 0.6164 - val_specific_output_custom_f1: 0.6201 - val_specific_output_custom_precision: 0.6201 - val_specific_output_custom_recall: 0.6201\n",
            "Epoch 14/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3536s\u001b[0m 12s/step - binary_output_accuracy: 0.6340 - binary_output_custom_f1: 0.0000e+00 - binary_output_precision: 0.0000e+00 - binary_output_recall: 0.0000e+00 - loss: 2.1102 - specific_output_categorical_accuracy: 0.6340 - specific_output_custom_f1: 0.6340 - specific_output_custom_precision: 0.6340 - specific_output_custom_recall: 0.6340 - val_binary_output_accuracy: 0.6164 - val_binary_output_custom_f1: 0.0000e+00 - val_binary_output_precision: 0.0000e+00 - val_binary_output_recall: 0.0000e+00 - val_loss: 2.1751 - val_specific_output_categorical_accuracy: 0.6164 - val_specific_output_custom_f1: 0.6201 - val_specific_output_custom_precision: 0.6201 - val_specific_output_custom_recall: 0.6201\n",
            "Epoch 15/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3494s\u001b[0m 11s/step - binary_output_accuracy: 0.6343 - binary_output_custom_f1: 0.0000e+00 - binary_output_precision: 0.0000e+00 - binary_output_recall: 0.0000e+00 - loss: 2.1148 - specific_output_categorical_accuracy: 0.6343 - specific_output_custom_f1: 0.6343 - specific_output_custom_precision: 0.6343 - specific_output_custom_recall: 0.6343 - val_binary_output_accuracy: 0.6164 - val_binary_output_custom_f1: 0.0000e+00 - val_binary_output_precision: 0.0000e+00 - val_binary_output_recall: 0.0000e+00 - val_loss: 2.1754 - val_specific_output_categorical_accuracy: 0.6164 - val_specific_output_custom_f1: 0.6201 - val_specific_output_custom_precision: 0.6201 - val_specific_output_custom_recall: 0.6201\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, MultiHeadAttention, LayerNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define the TransformerBlock class\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = Sequential(\n",
        "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs, training=training)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1, training=training)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "# Input layer\n",
        "input_layer = Input(shape=(X_with_clusters.shape[1], 1))\n",
        "\n",
        "# Shared layers\n",
        "x = Conv1D(filters=256, kernel_size=2, activation='relu')(input_layer)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Conv1D(filters=128, kernel_size=2, activation='relu')(x)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=256)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(100, activation='relu')(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "# Binary Classification Head (Goodware vs Malicious)\n",
        "binary_output = Dense(1, activation='sigmoid', name='binary_output')(x)\n",
        "\n",
        "# Group Classification Head\n",
        "group_output = Dense(6, activation='softmax', name='group_output')(x)\n",
        "\n",
        "# Specific Classification Head\n",
        "specific_output = Dense(12, activation='softmax', name='specific_output')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=[binary_output, group_output, specific_output])\n",
        "\n",
        "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Custom precision metric for multi-class classification\n",
        "def custom_precision(y_true, y_pred):\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "# Custom recall metric for multi-class classification\n",
        "def custom_recall(y_true, y_pred):\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "# Custom F1 score metric for multi-class classification\n",
        "def custom_f1(y_true, y_pred):\n",
        "    precision = custom_precision(y_true, y_pred)\n",
        "    recall = custom_recall(y_true, y_pred)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "    return f1\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'binary_output': 'binary_crossentropy', 'specific_output': 'categorical_crossentropy'},\n",
        "              metrics={'binary_output': ['accuracy', Precision(), Recall(), custom_f1],\n",
        "                  'specific_output': [CategoricalAccuracy(), custom_precision, custom_recall, custom_f1]})\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "\n",
        "# Mapping original labels to group labels\n",
        "# Assuming original labels are in the range [0, 11]\n",
        "label_to_group = {\n",
        "    0: 0,  # Goodware\n",
        "    1: 4,  # Critroni\n",
        "    2: 1,  # CryptLocker\n",
        "    3: 1,  # CryptoWall\n",
        "    4: 5,  # KOLLAH\n",
        "    5: 3,  # Kovter\n",
        "    6: 2,  # Locker\n",
        "    7: 3,  # MATSNU\n",
        "    8: 1,  # PGPCODER\n",
        "    9: 2,  # Reveton\n",
        "    10: 1,  # TeslaCrypt\n",
        "    11: 5,  # Trojan-Ransom\n",
        "}\n",
        "\n",
        "y_train_group = y_train.map(label_to_group)\n",
        "y_test_group = y_test.map(label_to_group)\n",
        "\n",
        "# One-hot encode the group and specific labels\n",
        "y_train_group_categorical = to_categorical(y_train_group, num_classes=6)\n",
        "y_train_categorical = to_categorical(y_train, num_classes=12)\n",
        "y_test_group_categorical = to_categorical(y_test_group, num_classes=6)\n",
        "y_test_categorical = to_categorical(y_test, num_classes=12)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_with_clusters,\n",
        "                    {'binary_output': y_train_binary, 'group_output': y_train_group_categorical, 'specific_output': y_train_categorical},\n",
        "                    epochs=15,\n",
        "                    batch_size=4,\n",
        "                    validation_data=(X_test_with_clusters, {'binary_output': y_test_binary, 'group_output': y_test_group_categorical, 'specific_output': y_test_categorical}),\n",
        "                    callbacks=[early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3SjipVBAUBe"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Generate predictions\n",
        "predictions = model.predict(X_test_with_clusters)\n",
        "\n",
        "# Binary predictions and metrics\n",
        "binary_predictions = (predictions[0] > 0.5).astype(int)  # Convert probabilities to 0 or 1\n",
        "binary_accuracy = accuracy_score(y_test_binary, binary_predictions)\n",
        "binary_precision = precision_score(y_test_binary, binary_predictions)\n",
        "binary_recall = recall_score(y_test_binary, binary_predictions)\n",
        "binary_f1 = f1_score(y_test_binary, binary_predictions)\n",
        "\n",
        "# Specific predictions and metrics\n",
        "specific_predictions = np.argmax(predictions[2], axis=1)\n",
        "specific_accuracy = accuracy_score(y_test, specific_predictions)\n",
        "specific_precision = precision_score(y_test, specific_predictions, average='macro')\n",
        "specific_recall = recall_score(y_test, specific_predictions, average='macro')\n",
        "specific_f1 = f1_score(y_test, specific_predictions, average='macro')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Binary Classification Metrics:\\n\"\n",
        "      f\"Accuracy: {binary_accuracy:.4f}\\n\"\n",
        "      f\"Precision: {binary_precision:.4f}\\n\"\n",
        "      f\"Recall: {binary_recall:.4f}\\n\"\n",
        "      f\"F1 Score: {binary_f1:.4f}\")\n",
        "\n",
        "print(f\"\\nSpecific Classification Metrics:\\n\"\n",
        "      f\"Accuracy: {specific_accuracy:.4f}\\n\"\n",
        "      f\"Precision: {specific_precision:.4f}\\n\"\n",
        "      f\"Recall: {specific_recall:.4f}\\n\"\n",
        "      f\"F1 Score: {specific_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tcex7Sk9rCtm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = model.predict(X_test_with_clusters)\n",
        "\n",
        "# Binary classification confusion matrix\n",
        "binary_preds = np.round(predictions[0]).astype(int)\n",
        "binary_cm = confusion_matrix(y_test_binary, binary_preds)\n",
        "\n",
        "\n",
        "# Specific classification confusion matrix\n",
        "specific_preds = np.argmax(predictions[2], axis=1)\n",
        "specific_cm = confusion_matrix(y_test, specific_preds)\n",
        "\n",
        "# Plot confusion matrices\n",
        "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "# Plot Binary classification confusion matrix\n",
        "plot_confusion_matrix(binary_cm, classes=['Goodware', 'Malicious'], title='Binary Classification Confusion Matrix')\n",
        "\n",
        "# Plot Specific classification confusion matrix\n",
        "specific_labels = ['Goodware', 'Critroni', 'CryptLocker', 'CryptoWall', 'KOLLAH', 'Kovter', 'Locker', 'MATSNU', 'PGPCODER', 'Reveton', 'TeslaCrypt', 'Trojan-Ransom']\n",
        "plot_confusion_matrix(specific_cm, classes=specific_labels, title='Specific Classification Confusion Matrix')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58n_8tORa5bi"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "# Plot the model\n",
        "plot_model(model, to_file='cnt_model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Display the model\n",
        "img = mpimg.imread('cnt_model.png')\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMSxvzX9QsYz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Generate predictions\n",
        "predictions = model.predict(X_test_with_clusters)\n",
        "\n",
        "# Binary predictions and metrics\n",
        "binary_predictions = (predictions[0] > 0.5).astype(int)  # Convert probabilities to 0 or 1\n",
        "binary_accuracy = accuracy_score(y_test_binary, binary_predictions)\n",
        "binary_precision = precision_score(y_test_binary, binary_predictions)\n",
        "binary_recall = recall_score(y_test_binary, binary_predictions)\n",
        "binary_f1 = f1_score(y_test_binary, binary_predictions)\n",
        "\n",
        "# Specific predictions and metrics\n",
        "specific_predictions = np.argmax(predictions[1], axis=1)\n",
        "specific_accuracy = accuracy_score(y_test, specific_predictions)\n",
        "specific_precision = precision_score(y_test, specific_predictions, average='macro')\n",
        "specific_recall = recall_score(y_test, specific_predictions, average='macro')\n",
        "specific_f1 = f1_score(y_test, specific_predictions, average='macro')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Binary Classification Metrics:\\n\"\n",
        "      f\"Accuracy: {binary_accuracy:.4f}\\n\"\n",
        "      f\"Precision: {binary_precision:.4f}\\n\"\n",
        "      f\"Recall: {binary_recall:.4f}\\n\"\n",
        "      f\"F1 Score: {binary_f1:.4f}\")\n",
        "\n",
        "print(f\"\\nSpecific Classification Metrics:\\n\"\n",
        "      f\"Accuracy: {specific_accuracy:.4f}\\n\"\n",
        "      f\"Precision: {specific_precision:.4f}\\n\"\n",
        "      f\"Recall: {specific_recall:.4f}\\n\"\n",
        "      f\"F1 Score: {specific_f1:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}