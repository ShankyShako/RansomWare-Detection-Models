{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvSStDNagxYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ea032f-bb36-4d4d-d596-c231d956a723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Reading the csv file\n",
        "df = pd.read_csv('/content/drive/MyDrive/RansomwareData.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8eU_XsxgzKL"
      },
      "outputs": [],
      "source": [
        "X = df.drop(df.columns[0], axis=1)\n",
        "X = X.drop(df.columns[1], axis=1)\n",
        "X = X.drop(df.columns[2], axis=1)\n",
        "y = df[df.columns[2]]\n",
        "\n",
        "y_binary = df[df.columns[1]]\n",
        "\n",
        "# Create group labels\n",
        "def convert_to_group(label):\n",
        "    if 1 <= label <= 3:\n",
        "        return 1\n",
        "    elif 4 <= label <= 6:\n",
        "        return 2\n",
        "    elif 7 <= label <= 9:\n",
        "        return 3\n",
        "    elif 10 <= label <= 12:\n",
        "        return 4\n",
        "    else:\n",
        "        return 0  # Assuming 0 is for goodware\n",
        "\n",
        "y_group = y.apply(convert_to_group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCMRmuq3g3sv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test, y_train_binary, y_test_binary, y_train_group, y_test_group = train_test_split(X, y, y_binary, y_group, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V6kapGjhjsCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynx8vTTTgfSV",
        "outputId": "56eaf501-1f43-433d-a27d-2bd8a35f0757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 213ms/step - loss: 0.0491 - val_loss: 0.0027\n",
            "Epoch 2/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 197ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 3/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 195ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 4/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 202ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 5/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 205ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 6/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 202ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 7/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 223ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 8/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 205ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 9/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 220ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 10/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 210ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 11/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 196ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 12/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 192ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 13/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 197ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 14/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 206ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 15/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 168ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 16/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 200ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 17/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 217ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 18/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 207ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 19/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 194ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 20/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 190ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 21/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 197ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 22/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 202ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 23/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 182ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 24/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 188ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 25/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 178ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 26/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 181ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 27/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 176ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 28/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 172ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 29/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 172ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 30/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 169ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 31/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 180ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 32/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 183ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 33/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 167ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 34/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 180ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 35/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 192ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 36/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 173ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 37/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 189ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 38/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 166ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 39/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 164ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 40/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 174ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 41/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 176ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 42/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 203ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 43/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 168ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 44/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 186ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 45/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 189ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 46/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 184ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 47/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 179ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 48/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 181ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 49/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 173ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 50/50\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 166ms/step - loss: 0.0017 - val_loss: 0.0018\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x794fb71eca60>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Define the autoencoder with a larger encoding dimension\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 256  # Increased dimension\n",
        "\n",
        "# Encoder\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
        "\n",
        "# Decoder\n",
        "decoder = Dense(input_dim, activation=\"sigmoid\")(encoder)\n",
        "\n",
        "# Autoencoder\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "\n",
        "# Compile the autoencoder with a lower learning rate\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(X_train, X_train, epochs=50, batch_size=4, validation_data=(X_test, X_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq3e7jWtgkQF",
        "outputId": "a9d40654-f9fd-4c46-9fa8-2ff793219367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
          ]
        }
      ],
      "source": [
        "# Extract the encoder part of the autoencoder\n",
        "encoder_model = Model(inputs=input_layer, outputs=encoder)\n",
        "\n",
        "# Transform the data to encoded representations\n",
        "X_train_encoded = encoder_model.predict(X_train)\n",
        "X_test_encoded = encoder_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qa3JGK5PgnXp",
        "outputId": "21912f32-5d74-46ff-e45a-2ac4f8542519"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m255\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m768\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m65,664\u001b[0m │ max_pooling1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8064\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ max_pooling1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │      \u001b[38;5;34m2,064,640\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m25,700\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m6,464\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ binary_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ group_output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m260\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ specific_output (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │            \u001b[38;5;34m780\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ max_pooling1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8064</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064,640</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ binary_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ group_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ specific_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">780</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,164,341\u001b[0m (8.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,164,341</span> (8.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,164,341\u001b[0m (8.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,164,341</span> (8.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - binary_output_accuracy: 0.7972 - group_output_accuracy: 0.6945 - loss: 2.5366 - specific_output_accuracy: 0.6444 - val_binary_output_accuracy: 0.9016 - val_group_output_accuracy: 0.7377 - val_loss: 1.6560 - val_specific_output_accuracy: 0.7738\n",
            "Epoch 2/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - binary_output_accuracy: 0.9066 - group_output_accuracy: 0.7797 - loss: 1.5335 - specific_output_accuracy: 0.7499 - val_binary_output_accuracy: 0.9475 - val_group_output_accuracy: 0.8230 - val_loss: 1.3094 - val_specific_output_accuracy: 0.7639\n",
            "Epoch 3/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - binary_output_accuracy: 0.9460 - group_output_accuracy: 0.8258 - loss: 1.2775 - specific_output_accuracy: 0.7899 - val_binary_output_accuracy: 0.9508 - val_group_output_accuracy: 0.8066 - val_loss: 1.2079 - val_specific_output_accuracy: 0.7672\n",
            "Epoch 4/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - binary_output_accuracy: 0.9525 - group_output_accuracy: 0.8579 - loss: 1.0439 - specific_output_accuracy: 0.8177 - val_binary_output_accuracy: 0.9770 - val_group_output_accuracy: 0.8557 - val_loss: 1.0348 - val_specific_output_accuracy: 0.8033\n",
            "Epoch 5/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - binary_output_accuracy: 0.9574 - group_output_accuracy: 0.8702 - loss: 0.9324 - specific_output_accuracy: 0.8347 - val_binary_output_accuracy: 0.9770 - val_group_output_accuracy: 0.8623 - val_loss: 1.0869 - val_specific_output_accuracy: 0.8098\n",
            "Epoch 6/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - binary_output_accuracy: 0.9608 - group_output_accuracy: 0.8718 - loss: 0.9419 - specific_output_accuracy: 0.8355 - val_binary_output_accuracy: 0.9738 - val_group_output_accuracy: 0.8590 - val_loss: 1.1001 - val_specific_output_accuracy: 0.7934\n",
            "Epoch 7/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - binary_output_accuracy: 0.9827 - group_output_accuracy: 0.8937 - loss: 0.6757 - specific_output_accuracy: 0.8646 - val_binary_output_accuracy: 0.9705 - val_group_output_accuracy: 0.8721 - val_loss: 1.2064 - val_specific_output_accuracy: 0.8328\n",
            "Epoch 8/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - binary_output_accuracy: 0.9708 - group_output_accuracy: 0.8971 - loss: 0.7088 - specific_output_accuracy: 0.8636 - val_binary_output_accuracy: 0.9738 - val_group_output_accuracy: 0.8557 - val_loss: 1.0290 - val_specific_output_accuracy: 0.8361\n",
            "Epoch 9/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - binary_output_accuracy: 0.9794 - group_output_accuracy: 0.9127 - loss: 0.7067 - specific_output_accuracy: 0.8741 - val_binary_output_accuracy: 0.9770 - val_group_output_accuracy: 0.8754 - val_loss: 1.1607 - val_specific_output_accuracy: 0.8131\n",
            "Epoch 10/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - binary_output_accuracy: 0.9866 - group_output_accuracy: 0.9235 - loss: 0.5785 - specific_output_accuracy: 0.8803 - val_binary_output_accuracy: 0.9639 - val_group_output_accuracy: 0.8590 - val_loss: 1.0959 - val_specific_output_accuracy: 0.8197\n",
            "Epoch 11/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - binary_output_accuracy: 0.9672 - group_output_accuracy: 0.9299 - loss: 0.5970 - specific_output_accuracy: 0.8962 - val_binary_output_accuracy: 0.9738 - val_group_output_accuracy: 0.8689 - val_loss: 1.0997 - val_specific_output_accuracy: 0.8197\n",
            "Epoch 12/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - binary_output_accuracy: 0.9907 - group_output_accuracy: 0.9404 - loss: 0.4492 - specific_output_accuracy: 0.9142 - val_binary_output_accuracy: 0.9770 - val_group_output_accuracy: 0.8787 - val_loss: 1.1218 - val_specific_output_accuracy: 0.8557\n",
            "Epoch 13/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 35ms/step - binary_output_accuracy: 0.9802 - group_output_accuracy: 0.9384 - loss: 0.4118 - specific_output_accuracy: 0.9277 - val_binary_output_accuracy: 0.9770 - val_group_output_accuracy: 0.8852 - val_loss: 1.2483 - val_specific_output_accuracy: 0.8197\n",
            "Epoch 14/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - binary_output_accuracy: 0.9797 - group_output_accuracy: 0.9403 - loss: 0.6134 - specific_output_accuracy: 0.9049 - val_binary_output_accuracy: 0.9770 - val_group_output_accuracy: 0.8623 - val_loss: 1.0434 - val_specific_output_accuracy: 0.8361\n",
            "Epoch 15/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - binary_output_accuracy: 0.9881 - group_output_accuracy: 0.9440 - loss: 0.3730 - specific_output_accuracy: 0.9333 - val_binary_output_accuracy: 0.9836 - val_group_output_accuracy: 0.8787 - val_loss: 1.1345 - val_specific_output_accuracy: 0.8230\n",
            "Epoch 16/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - binary_output_accuracy: 0.9938 - group_output_accuracy: 0.9563 - loss: 0.2780 - specific_output_accuracy: 0.9468 - val_binary_output_accuracy: 0.9770 - val_group_output_accuracy: 0.9016 - val_loss: 1.0488 - val_specific_output_accuracy: 0.8426\n",
            "Epoch 17/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - binary_output_accuracy: 0.9895 - group_output_accuracy: 0.9575 - loss: 0.2926 - specific_output_accuracy: 0.9463 - val_binary_output_accuracy: 0.9803 - val_group_output_accuracy: 0.8852 - val_loss: 1.0498 - val_specific_output_accuracy: 0.8525\n",
            "Epoch 18/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - binary_output_accuracy: 0.9901 - group_output_accuracy: 0.9643 - loss: 0.2342 - specific_output_accuracy: 0.9546 - val_binary_output_accuracy: 0.9836 - val_group_output_accuracy: 0.8852 - val_loss: 1.2109 - val_specific_output_accuracy: 0.8525\n",
            "Epoch 19/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - binary_output_accuracy: 0.9912 - group_output_accuracy: 0.9601 - loss: 0.2831 - specific_output_accuracy: 0.9481 - val_binary_output_accuracy: 0.9803 - val_group_output_accuracy: 0.8656 - val_loss: 1.2591 - val_specific_output_accuracy: 0.8459\n",
            "Epoch 20/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - binary_output_accuracy: 0.9911 - group_output_accuracy: 0.9613 - loss: 0.2488 - specific_output_accuracy: 0.9460 - val_binary_output_accuracy: 0.9738 - val_group_output_accuracy: 0.8721 - val_loss: 1.3064 - val_specific_output_accuracy: 0.8459\n",
            "Epoch 21/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - binary_output_accuracy: 0.9929 - group_output_accuracy: 0.9582 - loss: 0.2666 - specific_output_accuracy: 0.9413 - val_binary_output_accuracy: 0.9836 - val_group_output_accuracy: 0.8852 - val_loss: 1.4100 - val_specific_output_accuracy: 0.8426\n",
            "Epoch 22/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - binary_output_accuracy: 0.9812 - group_output_accuracy: 0.9424 - loss: 0.3573 - specific_output_accuracy: 0.9326 - val_binary_output_accuracy: 0.9836 - val_group_output_accuracy: 0.8787 - val_loss: 1.2436 - val_specific_output_accuracy: 0.8492\n",
            "Epoch 23/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - binary_output_accuracy: 0.9914 - group_output_accuracy: 0.9671 - loss: 0.2255 - specific_output_accuracy: 0.9537 - val_binary_output_accuracy: 0.9836 - val_group_output_accuracy: 0.8852 - val_loss: 1.2065 - val_specific_output_accuracy: 0.8557\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, MultiHeadAttention, LayerNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define the TransformerBlock class\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = Sequential(\n",
        "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# Shared layers\n",
        "x = Conv1D(filters=256, kernel_size=2, activation='relu')(input_layer)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Conv1D(filters=128, kernel_size=2, activation='relu')(x)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(100, activation='relu')(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "\n",
        "# Binary Classification Head (Goodware vs Malicious)\n",
        "binary_output = Dense(1, activation='sigmoid', name='binary_output')(x)\n",
        "\n",
        "# Group Classification Head\n",
        "group_output = Dense(4, activation='softmax', name='group_output')(x)\n",
        "\n",
        "# Specific Classification Head\n",
        "specific_output = Dense(12, activation='softmax', name='specific_output')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=[binary_output, group_output, specific_output])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'binary_output': 'binary_crossentropy', 'group_output': 'categorical_crossentropy', 'specific_output': 'categorical_crossentropy'},\n",
        "              metrics={'binary_output': 'accuracy', 'group_output': 'accuracy', 'specific_output': 'accuracy'})\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "\n",
        "# Mapping original labels to group labels\n",
        "# Assuming original labels are in the range [0, 11]\n",
        "label_to_group = {\n",
        "    0: 0,  # Goodware\n",
        "    1: 1,  # Critroni\n",
        "    2: 1,  # CryptLocker\n",
        "    3: 1,  # CryptoWall\n",
        "    4: 2,  # KOLLAH\n",
        "    5: 2,  # Kovter\n",
        "    6: 2,  # Locker\n",
        "    7: 3,  # MATSNU\n",
        "    8: 3,  # PGPCODER\n",
        "    9: 3,  # Reveton\n",
        "    10: 3,  # TeslaCrypt\n",
        "    11: 3,  # Trojan-Ransom\n",
        "}\n",
        "\n",
        "y_train_group = y_train.map(label_to_group)\n",
        "y_test_group = y_test.map(label_to_group)\n",
        "\n",
        "# One-hot encode the group and specific labels\n",
        "y_train_group_categorical = to_categorical(y_train_group, num_classes=4)\n",
        "y_train_categorical = to_categorical(y_train, num_classes=12)\n",
        "y_test_group_categorical = to_categorical(y_test_group, num_classes=4)\n",
        "y_test_categorical = to_categorical(y_test, num_classes=12)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_encoded,\n",
        "                    {'binary_output': y_train_binary, 'group_output': y_train_group_categorical, 'specific_output': y_train_categorical},\n",
        "                    epochs=500,\n",
        "                    batch_size=4,\n",
        "                    validation_data=(X_test_encoded, {'binary_output': y_test_binary, 'group_output': y_test_group_categorical, 'specific_output': y_test_categorical}),\n",
        "                    callbacks=[early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Generate predictions\n",
        "predictions = model.predict(X_test_encoded)\n",
        "\n",
        "# Binary predictions and metrics\n",
        "binary_predictions = (predictions[0] > 0.5).astype(int)  # Convert probabilities to 0 or 1\n",
        "binary_accuracy = accuracy_score(y_test_binary, binary_predictions)\n",
        "binary_precision = precision_score(y_test_binary, binary_predictions)\n",
        "binary_recall = recall_score(y_test_binary, binary_predictions)\n",
        "binary_f1 = f1_score(y_test_binary, binary_predictions)\n",
        "\n",
        "# Specific predictions and metrics\n",
        "specific_predictions = np.argmax(predictions[1], axis=1)\n",
        "specific_accuracy = accuracy_score(y_test, specific_predictions)\n",
        "specific_precision = precision_score(y_test, specific_predictions, average='macro')\n",
        "specific_recall = recall_score(y_test, specific_predictions, average='macro')\n",
        "specific_f1 = f1_score(y_test, specific_predictions, average='macro')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Binary Classification Metrics:\\n\"\n",
        "      f\"Accuracy: {binary_accuracy:.4f}\\n\"\n",
        "      f\"Precision: {binary_precision:.4f}\\n\"\n",
        "      f\"Recall: {binary_recall:.4f}\\n\"\n",
        "      f\"F1 Score: {binary_f1:.4f}\")\n",
        "\n",
        "print(f\"\\nSpecific Classification Metrics:\\n\"\n",
        "      f\"Accuracy: {specific_accuracy:.4f}\\n\"\n",
        "      f\"Precision: {specific_precision:.4f}\\n\"\n",
        "      f\"Recall: {specific_recall:.4f}\\n\"\n",
        "      f\"F1 Score: {specific_f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "U-cEsmpMYtto",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec645a88-1a28-4daf-cd1e-412b2f094015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
            "Binary Classification Metrics:\n",
            "Accuracy: 0.9738\n",
            "Precision: 0.9823\n",
            "Recall: 0.9487\n",
            "F1 Score: 0.9652\n",
            "\n",
            "Specific Classification Metrics:\n",
            "Accuracy: 0.6590\n",
            "Precision: 0.1150\n",
            "Recall: 0.1647\n",
            "F1 Score: 0.1295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUCaTL_x93Ht"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the history for each output\n",
        "binary_loss = history.history['binary_output_loss']\n",
        "val_binary_loss = history.history['val_binary_output_loss']\n",
        "group_loss = history.history['group_output_loss']\n",
        "val_group_loss = history.history['val_group_output_loss']\n",
        "specific_loss = history.history['specific_output_loss']\n",
        "val_specific_loss = history.history['val_specific_output_loss']\n",
        "\n",
        "binary_acc = history.history['binary_output_accuracy']\n",
        "val_binary_acc = history.history['val_binary_output_accuracy']\n",
        "group_acc = history.history['group_output_accuracy']\n",
        "val_group_acc = history.history['val_group_output_accuracy']\n",
        "specific_acc = history.history['specific_output_accuracy']\n",
        "val_specific_acc = history.history['val_specific_output_accuracy']\n",
        "\n",
        "# Plot loss\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(binary_loss, linestyle='--', label='Binary Output Loss')\n",
        "plt.plot(val_binary_loss, label='Val Binary Output Loss')\n",
        "plt.plot(group_loss, linestyle='--', label='Group Output Loss')\n",
        "plt.plot(val_group_loss, label='Val Group Output Loss')\n",
        "plt.plot(specific_loss, linestyle='--', label='Specific Output Loss')\n",
        "plt.plot(val_specific_loss, label='Val Specific Output Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(binary_acc, linestyle='--', label='Binary Output Accuracy')\n",
        "plt.plot(val_binary_acc, label='Val Binary Output Accuracy')\n",
        "plt.plot(group_acc, linestyle='--', label='Group Output Accuracy')\n",
        "plt.plot(val_group_acc, label='Val Group Output Accuracy')\n",
        "plt.plot(specific_acc, linestyle='--', label='Specific Output Accuracy')\n",
        "plt.plot(val_specific_acc, label='Val Specific Output Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tcex7Sk9rCtm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = model.predict(X_test_encoded)\n",
        "\n",
        "# Binary classification confusion matrix\n",
        "binary_preds = np.round(predictions[0]).astype(int)\n",
        "binary_cm = confusion_matrix(y_test_binary, binary_preds)\n",
        "\n",
        "# Group classification confusion matrix\n",
        "group_preds = np.argmax(predictions[1], axis=1)\n",
        "group_cm = confusion_matrix(y_test_group, group_preds)\n",
        "\n",
        "# Specific classification confusion matrix\n",
        "specific_preds = np.argmax(predictions[2], axis=1)\n",
        "specific_cm = confusion_matrix(y_test, specific_preds)\n",
        "\n",
        "# Plot confusion matrices\n",
        "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "# Plot Binary classification confusion matrix\n",
        "plot_confusion_matrix(binary_cm, classes=['Goodware', 'Ransomware'], title='Binary Classification Confusion Matrix')\n",
        "\n",
        "# Plot Group classification confusion matrix\n",
        "group_labels = ['Group 1', 'Group 2', 'Group 3', 'Group 4']\n",
        "plot_confusion_matrix(group_cm, classes=group_labels, title='Group Classification Confusion Matrix')\n",
        "\n",
        "# Plot Specific classification confusion matrix\n",
        "specific_labels = ['Goodware', 'Critroni', 'CryptLocker', 'CryptoWall', 'KOLLAH', 'Kovter', 'Locker', 'MATSNU', 'PGPCODER', 'Reveton', 'TeslaCrypt', 'Trojan-Ransom']\n",
        "plot_confusion_matrix(specific_cm, classes=specific_labels, title='Specific Classification Confusion Matrix')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}