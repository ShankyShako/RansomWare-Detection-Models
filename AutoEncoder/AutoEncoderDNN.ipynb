{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Reading the csv file\n",
        "df = pd.read_csv('/content/drive/MyDrive/RansomwareData.csv')\n"
      ],
      "metadata": {
        "id": "IvSStDNagxYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450f2649-7324-48ed-e233-1f3c3c2cf146"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(df.columns[0], axis=1)\n",
        "X = X.drop(df.columns[1], axis=1)\n",
        "X = X.drop(df.columns[2], axis=1)\n",
        "y = df[df.columns[2]]\n",
        "\n",
        "y_binary = df[df.columns[1]]\n",
        "\n",
        "# Create group labels\n",
        "def convert_to_group(label):\n",
        "    if 1 <= label <= 3:\n",
        "        return 1\n",
        "    elif 4 <= label <= 6:\n",
        "        return 2\n",
        "    elif 7 <= label <= 9:\n",
        "        return 3\n",
        "    elif 10 <= label <= 12:\n",
        "        return 4\n",
        "    else:\n",
        "        return 0  # Assuming 0 is for goodware\n",
        "\n",
        "y_group = y.apply(convert_to_group)"
      ],
      "metadata": {
        "id": "g8eU_XsxgzKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test, y_train_binary, y_test_binary, y_train_group, y_test_group = train_test_split(X, y, y_binary, y_group, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "VCMRmuq3g3sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynx8vTTTgfSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c11d66-8249-4881-80be-b1a8658886fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 125ms/step - loss: 0.1924 - val_loss: 0.0185\n",
            "Epoch 2/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 0.0128 - val_loss: 0.0073\n",
            "Epoch 3/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 147ms/step - loss: 0.0059 - val_loss: 0.0050\n",
            "Epoch 4/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - loss: 0.0037 - val_loss: 0.0042\n",
            "Epoch 5/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 0.0034 - val_loss: 0.0037\n",
            "Epoch 6/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - loss: 0.0030 - val_loss: 0.0034\n",
            "Epoch 7/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 125ms/step - loss: 0.0028 - val_loss: 0.0033\n",
            "Epoch 8/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 0.0027 - val_loss: 0.0031\n",
            "Epoch 9/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - loss: 0.0028 - val_loss: 0.0030\n",
            "Epoch 10/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - loss: 0.0028 - val_loss: 0.0029\n",
            "Epoch 11/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 12/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - loss: 0.0025 - val_loss: 0.0028\n",
            "Epoch 13/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 124ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 14/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 15/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - loss: 0.0025 - val_loss: 0.0026\n",
            "Epoch 16/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 123ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 17/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 18/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 19/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 20/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.0022 - val_loss: 0.0025\n",
            "Epoch 21/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 22/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 23/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 24/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 25/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 26/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 123ms/step - loss: 0.0022 - val_loss: 0.0024\n",
            "Epoch 27/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 28/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 29/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 30/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 97ms/step - loss: 0.0022 - val_loss: 0.0023\n",
            "Epoch 31/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 134ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 32/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 99ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 33/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - loss: 0.0019 - val_loss: 0.0023\n",
            "Epoch 34/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 35/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 36/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 37/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 38/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 39/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 40/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 41/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 42/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 43/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 44/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 45/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 46/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 47/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 121ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 48/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 49/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 50/50\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 0.0019 - val_loss: 0.0021\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d1853f9c130>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Define the autoencoder with a larger encoding dimension\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 64  # Increased dimension\n",
        "\n",
        "# Encoder\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
        "\n",
        "# Decoder\n",
        "decoder = Dense(input_dim, activation=\"sigmoid\")(encoder)\n",
        "\n",
        "# Autoencoder\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "#SDG\n",
        "# Compile the autoencoder with a lower learning rate\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, validation_data=(X_test, X_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the encoder part of the autoencoder\n",
        "encoder_model = Model(inputs=input_layer, outputs=encoder)\n",
        "\n",
        "# Transform the data to encoded representations\n",
        "X_train_encoded = encoder_model.predict(X_train)\n",
        "X_test_encoded = encoder_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "zq3e7jWtgkQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99e7ed8-7f0d-4588-f578-b49af7d6fc4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure input dimensions are correct\n",
        "encoding_dim = X_train_encoded.shape[1]\n",
        "\n",
        "# Input layer\n",
        "input_layer = Input(shape=(encoding_dim,))\n",
        "\n",
        "# Shared layers\n",
        "x = Dense(64, activation='relu')(input_layer)\n",
        "x = Dense(64, activation='relu')(x)  # Fixed duplicate use of input_layer\n",
        "\n",
        "# Binary Classification Head (Goodware vs Malicious)\n",
        "binary_output = Dense(1, activation='sigmoid', name='binary_output')(x)\n",
        "\n",
        "# Group Classification Head\n",
        "group_output = Dense(5, activation='softmax', name='group_output')(x)\n",
        "\n",
        "# Specific Classification Head\n",
        "specific_output = Dense(12, activation='softmax', name='specific_output')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=[binary_output, group_output, specific_output])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'binary_output': 'binary_crossentropy', 'group_output': 'categorical_crossentropy', 'specific_output': 'categorical_crossentropy'},\n",
        "              metrics={'binary_output': 'accuracy', 'group_output': 'accuracy', 'specific_output': 'accuracy'})\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "\n",
        "label_to_group = {\n",
        "    0: 0,  # Goodware\n",
        "    1: 1,  # Critroni\n",
        "    2: 1,  # CryptLocker\n",
        "    3: 1,  # CryptoWall\n",
        "    4: 2,  # KOLLAH\n",
        "    5: 2,  # Kovter\n",
        "    6: 2,  # Locker\n",
        "    7: 3,  # MATSNU\n",
        "    8: 3,  # PGPCODER\n",
        "    9: 3,  # Reveton\n",
        "    10: 4,  # TeslaCrypt\n",
        "    11: 4,  # Trojan-Ransom\n",
        "}\n",
        "# Assuming y_train and y_test are pandas Series\n",
        "y_train_group = y_train.map(label_to_group)\n",
        "y_test_group = y_test.map(label_to_group)\n",
        "\n",
        "# Binary labels (Goodware vs Malicious)\n",
        "y_train_binary = (y_train > 0).astype(int)\n",
        "y_test_binary = (y_test > 0).astype(int)\n",
        "\n",
        "# One-hot encode the group and specific labels\n",
        "y_train_group_categorical = to_categorical(y_train_group, num_classes=5)\n",
        "y_train_categorical = to_categorical(y_train, num_classes=12)\n",
        "y_test_group_categorical = to_categorical(y_test_group, num_classes=5)\n",
        "y_test_categorical = to_categorical(y_test, num_classes=12)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_encoded,\n",
        "                    {'binary_output': y_train_binary, 'group_output': y_train_group_categorical, 'specific_output': y_train_categorical},\n",
        "                    epochs=500,\n",
        "                    batch_size=4,\n",
        "                    validation_data=(X_test_encoded, {'binary_output': y_test_binary, 'group_output': y_test_group_categorical, 'specific_output': y_test_categorical}),\n",
        "                    callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qa3JGK5PgnXp",
        "outputId": "18eedd91-bf7b-4b43-9e79-7b0f1a5e6fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m4,160\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m4,160\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ binary_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ group_output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m325\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ specific_output (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │            \u001b[38;5;34m780\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ binary_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ group_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ specific_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">780</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,490\u001b[0m (37.07 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,490</span> (37.07 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,490\u001b[0m (37.07 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,490</span> (37.07 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - binary_output_accuracy: 0.7806 - group_output_accuracy: 0.5894 - loss: 3.5068 - specific_output_accuracy: 0.5748 - val_binary_output_accuracy: 0.8557 - val_group_output_accuracy: 0.7115 - val_loss: 2.0327 - val_specific_output_accuracy: 0.7148\n",
            "Epoch 2/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - binary_output_accuracy: 0.8761 - group_output_accuracy: 0.6796 - loss: 2.1358 - specific_output_accuracy: 0.6752 - val_binary_output_accuracy: 0.8689 - val_group_output_accuracy: 0.7311 - val_loss: 1.9929 - val_specific_output_accuracy: 0.7049\n",
            "Epoch 3/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - binary_output_accuracy: 0.8672 - group_output_accuracy: 0.7121 - loss: 2.1058 - specific_output_accuracy: 0.6890 - val_binary_output_accuracy: 0.8885 - val_group_output_accuracy: 0.6918 - val_loss: 1.9658 - val_specific_output_accuracy: 0.7279\n",
            "Epoch 4/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - binary_output_accuracy: 0.8758 - group_output_accuracy: 0.7097 - loss: 1.9565 - specific_output_accuracy: 0.7074 - val_binary_output_accuracy: 0.8656 - val_group_output_accuracy: 0.6721 - val_loss: 2.0402 - val_specific_output_accuracy: 0.6721\n",
            "Epoch 5/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - binary_output_accuracy: 0.8676 - group_output_accuracy: 0.7309 - loss: 1.9266 - specific_output_accuracy: 0.7094 - val_binary_output_accuracy: 0.9410 - val_group_output_accuracy: 0.7574 - val_loss: 1.7951 - val_specific_output_accuracy: 0.7279\n",
            "Epoch 6/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - binary_output_accuracy: 0.8869 - group_output_accuracy: 0.7104 - loss: 2.0109 - specific_output_accuracy: 0.6865 - val_binary_output_accuracy: 0.9344 - val_group_output_accuracy: 0.7607 - val_loss: 1.7418 - val_specific_output_accuracy: 0.7279\n",
            "Epoch 7/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - binary_output_accuracy: 0.9031 - group_output_accuracy: 0.7597 - loss: 1.7096 - specific_output_accuracy: 0.7300 - val_binary_output_accuracy: 0.8721 - val_group_output_accuracy: 0.7541 - val_loss: 1.8098 - val_specific_output_accuracy: 0.7279\n",
            "Epoch 8/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - binary_output_accuracy: 0.8751 - group_output_accuracy: 0.7521 - loss: 1.8179 - specific_output_accuracy: 0.7257 - val_binary_output_accuracy: 0.8525 - val_group_output_accuracy: 0.6689 - val_loss: 2.0568 - val_specific_output_accuracy: 0.6951\n",
            "Epoch 9/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - binary_output_accuracy: 0.8968 - group_output_accuracy: 0.7463 - loss: 1.7849 - specific_output_accuracy: 0.7202 - val_binary_output_accuracy: 0.9410 - val_group_output_accuracy: 0.7475 - val_loss: 1.8258 - val_specific_output_accuracy: 0.7180\n",
            "Epoch 10/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - binary_output_accuracy: 0.8976 - group_output_accuracy: 0.7382 - loss: 1.8021 - specific_output_accuracy: 0.7175 - val_binary_output_accuracy: 0.9049 - val_group_output_accuracy: 0.7443 - val_loss: 1.7383 - val_specific_output_accuracy: 0.7213\n",
            "Epoch 11/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.8992 - group_output_accuracy: 0.7445 - loss: 1.7037 - specific_output_accuracy: 0.7325 - val_binary_output_accuracy: 0.8689 - val_group_output_accuracy: 0.7475 - val_loss: 1.9272 - val_specific_output_accuracy: 0.7213\n",
            "Epoch 12/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9057 - group_output_accuracy: 0.7592 - loss: 1.6974 - specific_output_accuracy: 0.7375 - val_binary_output_accuracy: 0.8885 - val_group_output_accuracy: 0.7410 - val_loss: 1.8006 - val_specific_output_accuracy: 0.7311\n",
            "Epoch 13/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.8862 - group_output_accuracy: 0.7512 - loss: 1.7758 - specific_output_accuracy: 0.7262 - val_binary_output_accuracy: 0.9443 - val_group_output_accuracy: 0.7672 - val_loss: 1.6709 - val_specific_output_accuracy: 0.7344\n",
            "Epoch 14/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.8843 - group_output_accuracy: 0.7431 - loss: 1.7267 - specific_output_accuracy: 0.7224 - val_binary_output_accuracy: 0.9049 - val_group_output_accuracy: 0.7475 - val_loss: 1.6967 - val_specific_output_accuracy: 0.7311\n",
            "Epoch 15/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.8836 - group_output_accuracy: 0.7461 - loss: 1.7843 - specific_output_accuracy: 0.7177 - val_binary_output_accuracy: 0.8918 - val_group_output_accuracy: 0.7836 - val_loss: 1.7463 - val_specific_output_accuracy: 0.7475\n",
            "Epoch 16/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - binary_output_accuracy: 0.8766 - group_output_accuracy: 0.7874 - loss: 1.6642 - specific_output_accuracy: 0.7475 - val_binary_output_accuracy: 0.8885 - val_group_output_accuracy: 0.7607 - val_loss: 1.7561 - val_specific_output_accuracy: 0.7311\n",
            "Epoch 17/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - binary_output_accuracy: 0.9049 - group_output_accuracy: 0.7743 - loss: 1.5765 - specific_output_accuracy: 0.7453 - val_binary_output_accuracy: 0.9541 - val_group_output_accuracy: 0.7770 - val_loss: 1.6424 - val_specific_output_accuracy: 0.7377\n",
            "Epoch 18/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - binary_output_accuracy: 0.9043 - group_output_accuracy: 0.8067 - loss: 1.4904 - specific_output_accuracy: 0.7772 - val_binary_output_accuracy: 0.8721 - val_group_output_accuracy: 0.7672 - val_loss: 1.7684 - val_specific_output_accuracy: 0.7639\n",
            "Epoch 19/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9164 - group_output_accuracy: 0.7960 - loss: 1.5142 - specific_output_accuracy: 0.7599 - val_binary_output_accuracy: 0.9410 - val_group_output_accuracy: 0.7639 - val_loss: 1.6390 - val_specific_output_accuracy: 0.7574\n",
            "Epoch 20/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9142 - group_output_accuracy: 0.7862 - loss: 1.4965 - specific_output_accuracy: 0.7726 - val_binary_output_accuracy: 0.8787 - val_group_output_accuracy: 0.7148 - val_loss: 1.8434 - val_specific_output_accuracy: 0.7246\n",
            "Epoch 21/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9165 - group_output_accuracy: 0.7801 - loss: 1.5146 - specific_output_accuracy: 0.7493 - val_binary_output_accuracy: 0.8623 - val_group_output_accuracy: 0.7115 - val_loss: 1.9643 - val_specific_output_accuracy: 0.7016\n",
            "Epoch 22/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.8971 - group_output_accuracy: 0.7834 - loss: 1.5663 - specific_output_accuracy: 0.7617 - val_binary_output_accuracy: 0.8852 - val_group_output_accuracy: 0.7738 - val_loss: 1.8281 - val_specific_output_accuracy: 0.7344\n",
            "Epoch 23/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9125 - group_output_accuracy: 0.7873 - loss: 1.4873 - specific_output_accuracy: 0.7680 - val_binary_output_accuracy: 0.9377 - val_group_output_accuracy: 0.8000 - val_loss: 1.6501 - val_specific_output_accuracy: 0.7377\n",
            "Epoch 24/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9213 - group_output_accuracy: 0.7880 - loss: 1.4987 - specific_output_accuracy: 0.7558 - val_binary_output_accuracy: 0.8984 - val_group_output_accuracy: 0.7902 - val_loss: 1.7015 - val_specific_output_accuracy: 0.7574\n",
            "Epoch 25/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9123 - group_output_accuracy: 0.7700 - loss: 1.5783 - specific_output_accuracy: 0.7426 - val_binary_output_accuracy: 0.8951 - val_group_output_accuracy: 0.7803 - val_loss: 1.6917 - val_specific_output_accuracy: 0.7639\n",
            "Epoch 26/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - binary_output_accuracy: 0.9008 - group_output_accuracy: 0.7833 - loss: 1.5492 - specific_output_accuracy: 0.7469 - val_binary_output_accuracy: 0.9311 - val_group_output_accuracy: 0.8033 - val_loss: 1.6483 - val_specific_output_accuracy: 0.7672\n",
            "Epoch 27/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - binary_output_accuracy: 0.9041 - group_output_accuracy: 0.7749 - loss: 1.5825 - specific_output_accuracy: 0.7555 - val_binary_output_accuracy: 0.9311 - val_group_output_accuracy: 0.8066 - val_loss: 1.5702 - val_specific_output_accuracy: 0.7738\n",
            "Epoch 28/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - binary_output_accuracy: 0.8976 - group_output_accuracy: 0.7915 - loss: 1.5406 - specific_output_accuracy: 0.7588 - val_binary_output_accuracy: 0.9148 - val_group_output_accuracy: 0.8033 - val_loss: 1.6026 - val_specific_output_accuracy: 0.7672\n",
            "Epoch 29/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9084 - group_output_accuracy: 0.7814 - loss: 1.5445 - specific_output_accuracy: 0.7655 - val_binary_output_accuracy: 0.9016 - val_group_output_accuracy: 0.7770 - val_loss: 1.6662 - val_specific_output_accuracy: 0.7672\n",
            "Epoch 30/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9036 - group_output_accuracy: 0.8067 - loss: 1.4044 - specific_output_accuracy: 0.7899 - val_binary_output_accuracy: 0.9180 - val_group_output_accuracy: 0.8000 - val_loss: 1.6641 - val_specific_output_accuracy: 0.7508\n",
            "Epoch 31/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9107 - group_output_accuracy: 0.7984 - loss: 1.4282 - specific_output_accuracy: 0.7856 - val_binary_output_accuracy: 0.9246 - val_group_output_accuracy: 0.7967 - val_loss: 1.6336 - val_specific_output_accuracy: 0.7836\n",
            "Epoch 32/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9211 - group_output_accuracy: 0.7985 - loss: 1.3869 - specific_output_accuracy: 0.7749 - val_binary_output_accuracy: 0.9508 - val_group_output_accuracy: 0.8131 - val_loss: 1.6122 - val_specific_output_accuracy: 0.7475\n",
            "Epoch 33/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9166 - group_output_accuracy: 0.7989 - loss: 1.3197 - specific_output_accuracy: 0.7884 - val_binary_output_accuracy: 0.9377 - val_group_output_accuracy: 0.7934 - val_loss: 1.6192 - val_specific_output_accuracy: 0.7508\n",
            "Epoch 34/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9285 - group_output_accuracy: 0.8021 - loss: 1.3823 - specific_output_accuracy: 0.7849 - val_binary_output_accuracy: 0.9082 - val_group_output_accuracy: 0.7869 - val_loss: 1.7214 - val_specific_output_accuracy: 0.7508\n",
            "Epoch 35/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9038 - group_output_accuracy: 0.7872 - loss: 1.4264 - specific_output_accuracy: 0.7856 - val_binary_output_accuracy: 0.9443 - val_group_output_accuracy: 0.7934 - val_loss: 1.5640 - val_specific_output_accuracy: 0.7475\n",
            "Epoch 36/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - binary_output_accuracy: 0.9215 - group_output_accuracy: 0.8108 - loss: 1.4327 - specific_output_accuracy: 0.7795 - val_binary_output_accuracy: 0.8787 - val_group_output_accuracy: 0.7738 - val_loss: 1.7148 - val_specific_output_accuracy: 0.7410\n",
            "Epoch 37/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - binary_output_accuracy: 0.9085 - group_output_accuracy: 0.8038 - loss: 1.3756 - specific_output_accuracy: 0.7840 - val_binary_output_accuracy: 0.9180 - val_group_output_accuracy: 0.8098 - val_loss: 1.6340 - val_specific_output_accuracy: 0.7607\n",
            "Epoch 38/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - binary_output_accuracy: 0.9179 - group_output_accuracy: 0.7907 - loss: 1.4332 - specific_output_accuracy: 0.7826 - val_binary_output_accuracy: 0.9213 - val_group_output_accuracy: 0.7803 - val_loss: 1.7348 - val_specific_output_accuracy: 0.7639\n",
            "Epoch 39/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - binary_output_accuracy: 0.9300 - group_output_accuracy: 0.7972 - loss: 1.3160 - specific_output_accuracy: 0.7890 - val_binary_output_accuracy: 0.9377 - val_group_output_accuracy: 0.7836 - val_loss: 1.6466 - val_specific_output_accuracy: 0.7508\n",
            "Epoch 40/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9203 - group_output_accuracy: 0.7878 - loss: 1.4154 - specific_output_accuracy: 0.7682 - val_binary_output_accuracy: 0.9410 - val_group_output_accuracy: 0.7934 - val_loss: 1.6738 - val_specific_output_accuracy: 0.7672\n",
            "Epoch 41/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - binary_output_accuracy: 0.9113 - group_output_accuracy: 0.8084 - loss: 1.3566 - specific_output_accuracy: 0.7963 - val_binary_output_accuracy: 0.9377 - val_group_output_accuracy: 0.8000 - val_loss: 1.6164 - val_specific_output_accuracy: 0.7574\n",
            "Epoch 42/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9310 - group_output_accuracy: 0.8074 - loss: 1.2893 - specific_output_accuracy: 0.7955 - val_binary_output_accuracy: 0.9344 - val_group_output_accuracy: 0.7902 - val_loss: 1.6918 - val_specific_output_accuracy: 0.7541\n",
            "Epoch 43/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9132 - group_output_accuracy: 0.7738 - loss: 1.4444 - specific_output_accuracy: 0.7682 - val_binary_output_accuracy: 0.9541 - val_group_output_accuracy: 0.7869 - val_loss: 1.5993 - val_specific_output_accuracy: 0.7410\n",
            "Epoch 44/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9089 - group_output_accuracy: 0.8094 - loss: 1.4038 - specific_output_accuracy: 0.7965 - val_binary_output_accuracy: 0.9410 - val_group_output_accuracy: 0.8066 - val_loss: 1.5545 - val_specific_output_accuracy: 0.7508\n",
            "Epoch 45/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9338 - group_output_accuracy: 0.8093 - loss: 1.2968 - specific_output_accuracy: 0.7876 - val_binary_output_accuracy: 0.9541 - val_group_output_accuracy: 0.7836 - val_loss: 1.5116 - val_specific_output_accuracy: 0.7738\n",
            "Epoch 46/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - binary_output_accuracy: 0.9269 - group_output_accuracy: 0.7783 - loss: 1.3796 - specific_output_accuracy: 0.7664 - val_binary_output_accuracy: 0.9049 - val_group_output_accuracy: 0.7607 - val_loss: 1.8803 - val_specific_output_accuracy: 0.7311\n",
            "Epoch 47/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - binary_output_accuracy: 0.9101 - group_output_accuracy: 0.7911 - loss: 1.3658 - specific_output_accuracy: 0.7670 - val_binary_output_accuracy: 0.9639 - val_group_output_accuracy: 0.7836 - val_loss: 1.6342 - val_specific_output_accuracy: 0.7639\n",
            "Epoch 48/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - binary_output_accuracy: 0.9235 - group_output_accuracy: 0.7877 - loss: 1.4200 - specific_output_accuracy: 0.7774 - val_binary_output_accuracy: 0.9016 - val_group_output_accuracy: 0.7967 - val_loss: 1.6949 - val_specific_output_accuracy: 0.7541\n",
            "Epoch 49/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9123 - group_output_accuracy: 0.8008 - loss: 1.3281 - specific_output_accuracy: 0.7920 - val_binary_output_accuracy: 0.9344 - val_group_output_accuracy: 0.8262 - val_loss: 1.5621 - val_specific_output_accuracy: 0.8000\n",
            "Epoch 50/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9083 - group_output_accuracy: 0.8101 - loss: 1.3554 - specific_output_accuracy: 0.7896 - val_binary_output_accuracy: 0.9016 - val_group_output_accuracy: 0.7574 - val_loss: 1.8818 - val_specific_output_accuracy: 0.7344\n",
            "Epoch 51/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9193 - group_output_accuracy: 0.7851 - loss: 1.3855 - specific_output_accuracy: 0.7824 - val_binary_output_accuracy: 0.9410 - val_group_output_accuracy: 0.7770 - val_loss: 1.6587 - val_specific_output_accuracy: 0.7475\n",
            "Epoch 52/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - binary_output_accuracy: 0.9424 - group_output_accuracy: 0.7978 - loss: 1.2733 - specific_output_accuracy: 0.7994 - val_binary_output_accuracy: 0.9246 - val_group_output_accuracy: 0.7738 - val_loss: 1.6622 - val_specific_output_accuracy: 0.7672\n",
            "Epoch 53/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_output_accuracy: 0.9201 - group_output_accuracy: 0.8148 - loss: 1.2719 - specific_output_accuracy: 0.7970 - val_binary_output_accuracy: 0.9246 - val_group_output_accuracy: 0.8098 - val_loss: 1.6312 - val_specific_output_accuracy: 0.7869\n",
            "Epoch 54/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - binary_output_accuracy: 0.9214 - group_output_accuracy: 0.7989 - loss: 1.2987 - specific_output_accuracy: 0.7933 - val_binary_output_accuracy: 0.9311 - val_group_output_accuracy: 0.7672 - val_loss: 1.6920 - val_specific_output_accuracy: 0.7541\n",
            "Epoch 55/500\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - binary_output_accuracy: 0.9254 - group_output_accuracy: 0.8150 - loss: 1.2115 - specific_output_accuracy: 0.8012 - val_binary_output_accuracy: 0.9082 - val_group_output_accuracy: 0.7738 - val_loss: 1.8415 - val_specific_output_accuracy: 0.7639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Generate predictions\n",
        "predictions = model.predict(X_test_encoded)\n",
        "\n",
        "# Binary predictions and metrics\n",
        "binary_predictions = (predictions[0] > 0.5).astype(int)  # Convert probabilities to 0 or 1\n",
        "binary_accuracy = accuracy_score(y_test_binary, binary_predictions)\n",
        "binary_precision = precision_score(y_test_binary, binary_predictions)\n",
        "binary_recall = recall_score(y_test_binary, binary_predictions)\n",
        "binary_f1 = f1_score(y_test_binary, binary_predictions)\n",
        "# Specific predictions and metrics\n",
        "specific_predictions = np.argmax(predictions[2], axis=1)\n",
        "specific_accuracy = accuracy_score(y_test, specific_predictions)\n",
        "specific_precision = precision_score(y_test, specific_predictions, average='macro')\n",
        "specific_recall = recall_score(y_test, specific_predictions, average='macro')\n",
        "specific_f1 = f1_score(y_test, specific_predictions, average='macro')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Binary Classification Metrics:\\n\"\n",
        "      f\"Accuracy: {binary_accuracy:.4f}\\n\"\n",
        "      f\"Precision: {binary_precision:.4f}\\n\"\n",
        "      f\"Recall: {binary_recall:.4f}\\n\"\n",
        "      f\"F1 Score: {binary_f1:.4f}\")\n",
        "\n",
        "print(f\"\\nSpecific Classification Metrics:\\n\"\n",
        "      f\"Accuracy: {specific_accuracy:.4f}\\n\"\n",
        "      f\"Precision: {specific_precision:.4f}\\n\"\n",
        "      f\"Recall: {specific_recall:.4f}\\n\"\n",
        "      f\"F1 Score: {specific_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPk6-KUQ4mdH",
        "outputId": "4f6e63a4-9466-42a5-c457-d0fdc389ecae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Binary Classification Metrics:\n",
            "Accuracy: 0.9541\n",
            "Precision: 0.9558\n",
            "Recall: 0.9231\n",
            "F1 Score: 0.9391\n",
            "\n",
            "Specific Classification Metrics:\n",
            "Accuracy: 0.7738\n",
            "Precision: 0.3640\n",
            "Recall: 0.3387\n",
            "F1 Score: 0.3414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the history for each output\n",
        "binary_loss = history.history['binary_output_loss']\n",
        "val_binary_loss = history.history['val_binary_output_loss']\n",
        "specific_loss = history.history['specific_output_loss']\n",
        "val_specific_loss = history.history['val_specific_output_loss']\n",
        "\n",
        "binary_acc = history.history['binary_output_accuracy']\n",
        "val_binary_acc = history.history['val_binary_output_accuracy']\n",
        "specific_acc = history.history['specific_output_accuracy']\n",
        "val_specific_acc = history.history['val_specific_output_accuracy']\n",
        "\n",
        "# Plot loss\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(binary_loss, linestyle='--', label='Binary Output Loss')\n",
        "plt.plot(val_binary_loss, label='Val Binary Output Loss')\n",
        "plt.plot(specific_loss, linestyle='--', label='Specific Output Loss')\n",
        "plt.plot(val_specific_loss, label='Val Specific Output Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(binary_acc, linestyle='--', label='Binary Output Accuracy')\n",
        "plt.plot(val_binary_acc, label='Val Binary Output Accuracy')\n",
        "plt.plot(group_acc, linestyle='--', label='Group Output Accuracy')\n",
        "plt.plot(val_group_acc, label='Val Group Output Accuracy')\n",
        "plt.plot(specific_acc, linestyle='--', label='Specific Output Accuracy')\n",
        "plt.plot(val_specific_acc, label='Val Specific Output Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hHKqPFo4gqGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = model.predict(X_test_encoded)\n",
        "\n",
        "# Binary classification confusion matrix\n",
        "binary_preds = np.round(predictions[0]).astype(int)\n",
        "binary_cm = confusion_matrix(y_test_binary, binary_preds)\n",
        "\n",
        "# Group classification confusion matrix\n",
        "group_preds = np.argmax(predictions[1], axis=1)\n",
        "group_cm = confusion_matrix(y_test_group, group_preds)\n",
        "\n",
        "# Specific classification confusion matrix\n",
        "specific_preds = np.argmax(predictions[2], axis=1)\n",
        "specific_cm = confusion_matrix(y_test, specific_preds)\n",
        "\n",
        "# Plot confusion matrices\n",
        "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "# Plot Binary classification confusion matrix\n",
        "plot_confusion_matrix(binary_cm, classes=['Goodware', 'Malicious'], title='Binary Classification Confusion Matrix')\n",
        "\n",
        "# Plot Group classification confusion matrix\n",
        "group_labels = ['Group 1', 'Group 2', 'Group 3', 'Group 4']\n",
        "plot_confusion_matrix(group_cm, classes=group_labels, title='Group Classification Confusion Matrix')\n",
        "\n",
        "# Plot Specific classification confusion matrix\n",
        "specific_labels = ['Goodware', 'Critroni', 'CryptLocker', 'CryptoWall', 'KOLLAH', 'Kovter', 'Locker', 'MATSNU', 'PGPCODER', 'Reveton', 'TeslaCrypt', 'Trojan-Ransom']\n",
        "plot_confusion_matrix(specific_cm, classes=specific_labels, title='Specific Classification Confusion Matrix')\n"
      ],
      "metadata": {
        "id": "tuqHQlnKZy71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Generate predictions\n",
        "predictions = model.predict(X_test_encoded)\n",
        "\n",
        "# Binary predictions and metrics\n",
        "binary_predictions = (predictions[0] > 0.5).astype(int)  # Convert probabilities to 0 or 1\n",
        "binary_accuracy = accuracy_score(y_test_binary, binary_predictions)\n",
        "binary_precision = precision_score(y_test_binary, binary_predictions)\n",
        "binary_recall = recall_score(y_test_binary, binary_predictions)\n",
        "binary_f1 = f1_score(y_test_binary, binary_predictions)\n",
        "\n",
        "# Specific predictions and metrics\n",
        "specific_predictions = np.argmax(predictions[2], axis=1)\n",
        "specific_accuracy = accuracy_score(y_test, specific_predictions)\n",
        "specific_precision = precision_score(y_test, specific_predictions, average='macro')\n",
        "specific_recall = recall_score(y_test, specific_predictions, average='macro')\n",
        "specific_f1 = f1_score(y_test, specific_predictions, average='macro')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Binary Classification Metrics:\\n\"\n",
        "      f\"Accuracy: {binary_accuracy:.4f}\\n\"\n",
        "      f\"Precision: {binary_precision:.4f}\\n\"\n",
        "      f\"Recall: {binary_recall:.4f}\\n\"\n",
        "      f\"F1 Score: {binary_f1:.4f}\")\n",
        "\n",
        "print(f\"\\nSpecific Classification Metrics:\\n\"\n",
        "      f\"Accuracy: {specific_accuracy:.4f}\\n\"\n",
        "      f\"Precision: {specific_precision:.4f}\\n\"\n",
        "      f\"Recall: {specific_recall:.4f}\\n\"\n",
        "      f\"F1 Score: {specific_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH7LcJvCULCV",
        "outputId": "f302b3eb-63d0-4973-8ee6-d838fd7b1d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Binary Classification Metrics:\n",
            "Accuracy: 0.4033\n",
            "Precision: 0.3843\n",
            "Recall: 0.9231\n",
            "F1 Score: 0.5427\n",
            "\n",
            "Specific Classification Metrics:\n",
            "Accuracy: 0.0295\n",
            "Precision: 0.0095\n",
            "Recall: 0.0608\n",
            "F1 Score: 0.0151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "# Plot the model\n",
        "plot_model(model, to_file='dnn_model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Display the model\n",
        "img = mpimg.imread('dnn_model.png')\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "J04eG9ZJk-nJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}