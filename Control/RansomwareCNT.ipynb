{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvSStDNagxYQ",
        "outputId": "725c16ee-0087-4237-c8fc-84bd03692748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Reading the csv file\n",
        "df = pd.read_csv('/content/drive/MyDrive/RansomwareData.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8eU_XsxgzKL"
      },
      "outputs": [],
      "source": [
        "X = df.drop(df.columns[0], axis=1)\n",
        "X = X.drop(df.columns[1], axis=1)\n",
        "X = X.drop(df.columns[2], axis=1)\n",
        "y = df[df.columns[2]]\n",
        "\n",
        "y_binary = df[df.columns[1]]\n",
        "\n",
        "# Create group labels\n",
        "def convert_to_group(label):\n",
        "    if 1 <= label <= 3:\n",
        "        return 1\n",
        "    elif 4 <= label <= 6:\n",
        "        return 2\n",
        "    elif 7 <= label <= 9:\n",
        "        return 3\n",
        "    elif 10 <= label <= 12:\n",
        "        return 4\n",
        "    else:\n",
        "        return 0  # Assuming 0 is for goodware\n",
        "\n",
        "y_group = y.apply(convert_to_group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCMRmuq3g3sv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test, y_train_binary, y_test_binary, y_train_group, y_test_group = train_test_split(X, y, y_binary, y_group, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qa3JGK5PgnXp",
        "outputId": "f8332322-6636-4c80-c362-f827a2de7846"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30967</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30966</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15483</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15482</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7741</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7741</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">330,240</span> │ max_pooling1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)        │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">990848</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_block_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">253,657,344</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ binary_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ specific_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">780</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30967\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30966\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │            \u001b[38;5;34m768\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15483\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15482\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │         \u001b[38;5;34m65,664\u001b[0m │ max_pooling1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7741\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_block_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7741\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m330,240\u001b[0m │ max_pooling1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)        │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m990848\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ transformer_block_1[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m253,657,344\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m25,700\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m6,464\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ binary_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ specific_output (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │            \u001b[38;5;34m780\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">254,087,025</span> (969.27 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m254,087,025\u001b[0m (969.27 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">254,087,025</span> (969.27 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m254,087,025\u001b[0m (969.27 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3845s\u001b[0m 13s/step - binary_output_accuracy: 0.5349 - binary_output_custom_f1: 0.2136 - binary_output_precision_1: 0.3852 - binary_output_recall_1: 0.4065 - loss: 159.4024 - specific_output_categorical_accuracy: 0.3799 - specific_output_custom_f1: 0.3804 - specific_output_custom_precision: 0.3821 - specific_output_custom_recall: 0.3799 - val_binary_output_accuracy: 0.5082 - val_binary_output_custom_f1: 0.5521 - val_binary_output_precision_1: 0.4382 - val_binary_output_recall_1: 1.0000 - val_loss: 13.2575 - val_specific_output_categorical_accuracy: 0.4262 - val_specific_output_custom_f1: 0.4538 - val_specific_output_custom_precision: 0.4946 - val_specific_output_custom_recall: 0.4253\n",
            "Epoch 2/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3795s\u001b[0m 12s/step - binary_output_accuracy: 0.7403 - binary_output_custom_f1: 0.4768 - binary_output_precision_1: 0.6496 - binary_output_recall_1: 0.6793 - loss: 8.0879 - specific_output_categorical_accuracy: 0.5106 - specific_output_custom_f1: 0.5067 - specific_output_custom_precision: 0.5191 - specific_output_custom_recall: 0.4986 - val_binary_output_accuracy: 0.8754 - val_binary_output_custom_f1: 0.7383 - val_binary_output_precision_1: 0.7582 - val_binary_output_recall_1: 0.9915 - val_loss: 3.3862 - val_specific_output_categorical_accuracy: 0.6393 - val_specific_output_custom_f1: 0.6430 - val_specific_output_custom_precision: 0.6483 - val_specific_output_custom_recall: 0.6396\n",
            "Epoch 3/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3846s\u001b[0m 13s/step - binary_output_accuracy: 0.8167 - binary_output_custom_f1: 0.6044 - binary_output_precision_1: 0.7475 - binary_output_recall_1: 0.7617 - loss: 3.3035 - specific_output_categorical_accuracy: 0.6236 - specific_output_custom_f1: 0.6282 - specific_output_custom_precision: 0.6609 - specific_output_custom_recall: 0.6071 - val_binary_output_accuracy: 0.8951 - val_binary_output_custom_f1: 0.7130 - val_binary_output_precision_1: 0.8295 - val_binary_output_recall_1: 0.9145 - val_loss: 3.1434 - val_specific_output_categorical_accuracy: 0.5738 - val_specific_output_custom_f1: 0.5776 - val_specific_output_custom_precision: 0.5996 - val_specific_output_custom_recall: 0.5617\n",
            "Epoch 4/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3848s\u001b[0m 13s/step - binary_output_accuracy: 0.8458 - binary_output_custom_f1: 0.6061 - binary_output_precision_1: 0.8176 - binary_output_recall_1: 0.7789 - loss: 2.8297 - specific_output_categorical_accuracy: 0.6278 - specific_output_custom_f1: 0.6403 - specific_output_custom_precision: 0.6949 - specific_output_custom_recall: 0.6099 - val_binary_output_accuracy: 0.8984 - val_binary_output_custom_f1: 0.7091 - val_binary_output_precision_1: 0.8583 - val_binary_output_recall_1: 0.8803 - val_loss: 2.1550 - val_specific_output_categorical_accuracy: 0.6787 - val_specific_output_custom_f1: 0.6898 - val_specific_output_custom_precision: 0.7684 - val_specific_output_custom_recall: 0.6429\n",
            "Epoch 5/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3900s\u001b[0m 13s/step - binary_output_accuracy: 0.8668 - binary_output_custom_f1: 0.6378 - binary_output_precision_1: 0.8181 - binary_output_recall_1: 0.8250 - loss: 2.1095 - specific_output_categorical_accuracy: 0.6919 - specific_output_custom_f1: 0.7023 - specific_output_custom_precision: 0.7412 - specific_output_custom_recall: 0.6750 - val_binary_output_accuracy: 0.8262 - val_binary_output_custom_f1: 0.7127 - val_binary_output_precision_1: 0.6905 - val_binary_output_recall_1: 0.9915 - val_loss: 3.1623 - val_specific_output_categorical_accuracy: 0.5672 - val_specific_output_custom_f1: 0.5602 - val_specific_output_custom_precision: 0.6017 - val_specific_output_custom_recall: 0.5357\n",
            "Epoch 6/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3880s\u001b[0m 13s/step - binary_output_accuracy: 0.8807 - binary_output_custom_f1: 0.6632 - binary_output_precision_1: 0.8340 - binary_output_recall_1: 0.8486 - loss: 2.0868 - specific_output_categorical_accuracy: 0.6684 - specific_output_custom_f1: 0.6762 - specific_output_custom_precision: 0.7444 - specific_output_custom_recall: 0.6332 - val_binary_output_accuracy: 0.8098 - val_binary_output_custom_f1: 0.4857 - val_binary_output_precision_1: 0.9836 - val_binary_output_recall_1: 0.5128 - val_loss: 1.5330 - val_specific_output_categorical_accuracy: 0.6885 - val_specific_output_custom_f1: 0.7265 - val_specific_output_custom_precision: 0.8312 - val_specific_output_custom_recall: 0.6656\n",
            "Epoch 7/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3962s\u001b[0m 13s/step - binary_output_accuracy: 0.8987 - binary_output_custom_f1: 0.7111 - binary_output_precision_1: 0.8587 - binary_output_recall_1: 0.8609 - loss: 1.3593 - specific_output_categorical_accuracy: 0.7320 - specific_output_custom_f1: 0.7476 - specific_output_custom_precision: 0.8249 - specific_output_custom_recall: 0.7017 - val_binary_output_accuracy: 0.9410 - val_binary_output_custom_f1: 0.7294 - val_binary_output_precision_1: 0.9626 - val_binary_output_recall_1: 0.8803 - val_loss: 1.7902 - val_specific_output_categorical_accuracy: 0.6656 - val_specific_output_custom_f1: 0.6823 - val_specific_output_custom_precision: 0.7067 - val_specific_output_custom_recall: 0.6656\n",
            "Epoch 8/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3794s\u001b[0m 12s/step - binary_output_accuracy: 0.9067 - binary_output_custom_f1: 0.7344 - binary_output_precision_1: 0.8710 - binary_output_recall_1: 0.8846 - loss: 1.2420 - specific_output_categorical_accuracy: 0.7422 - specific_output_custom_f1: 0.7554 - specific_output_custom_precision: 0.8375 - specific_output_custom_recall: 0.7101 - val_binary_output_accuracy: 0.8656 - val_binary_output_custom_f1: 0.7338 - val_binary_output_precision_1: 0.7436 - val_binary_output_recall_1: 0.9915 - val_loss: 2.3549 - val_specific_output_categorical_accuracy: 0.6131 - val_specific_output_custom_f1: 0.6518 - val_specific_output_custom_precision: 0.7846 - val_specific_output_custom_recall: 0.5812\n",
            "Epoch 9/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3769s\u001b[0m 12s/step - binary_output_accuracy: 0.9051 - binary_output_custom_f1: 0.7037 - binary_output_precision_1: 0.8821 - binary_output_recall_1: 0.8637 - loss: 1.3543 - specific_output_categorical_accuracy: 0.7111 - specific_output_custom_f1: 0.7272 - specific_output_custom_precision: 0.7973 - specific_output_custom_recall: 0.6832 - val_binary_output_accuracy: 0.9213 - val_binary_output_custom_f1: 0.7052 - val_binary_output_precision_1: 0.9895 - val_binary_output_recall_1: 0.8034 - val_loss: 1.2712 - val_specific_output_categorical_accuracy: 0.7607 - val_specific_output_custom_f1: 0.7897 - val_specific_output_custom_precision: 0.8972 - val_specific_output_custom_recall: 0.7305\n",
            "Epoch 10/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3757s\u001b[0m 12s/step - binary_output_accuracy: 0.9579 - binary_output_custom_f1: 0.8123 - binary_output_precision_1: 0.9497 - binary_output_recall_1: 0.9363 - loss: 0.8857 - specific_output_categorical_accuracy: 0.7944 - specific_output_custom_f1: 0.8016 - specific_output_custom_precision: 0.8853 - specific_output_custom_recall: 0.7489 - val_binary_output_accuracy: 0.8230 - val_binary_output_custom_f1: 0.5104 - val_binary_output_precision_1: 1.0000 - val_binary_output_recall_1: 0.5385 - val_loss: 2.4593 - val_specific_output_categorical_accuracy: 0.6918 - val_specific_output_custom_f1: 0.7084 - val_specific_output_custom_precision: 0.7381 - val_specific_output_custom_recall: 0.6883\n",
            "Epoch 11/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3742s\u001b[0m 12s/step - binary_output_accuracy: 0.9125 - binary_output_custom_f1: 0.7124 - binary_output_precision_1: 0.8959 - binary_output_recall_1: 0.8656 - loss: 1.2948 - specific_output_categorical_accuracy: 0.7520 - specific_output_custom_f1: 0.7645 - specific_output_custom_precision: 0.8356 - specific_output_custom_recall: 0.7217 - val_binary_output_accuracy: 0.9344 - val_binary_output_custom_f1: 0.7687 - val_binary_output_precision_1: 0.8702 - val_binary_output_recall_1: 0.9744 - val_loss: 0.8841 - val_specific_output_categorical_accuracy: 0.7770 - val_specific_output_custom_f1: 0.8198 - val_specific_output_custom_precision: 0.9188 - val_specific_output_custom_recall: 0.7597\n",
            "Epoch 12/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3736s\u001b[0m 12s/step - binary_output_accuracy: 0.9537 - binary_output_custom_f1: 0.8328 - binary_output_precision_1: 0.9389 - binary_output_recall_1: 0.9382 - loss: 0.8654 - specific_output_categorical_accuracy: 0.7928 - specific_output_custom_f1: 0.8055 - specific_output_custom_precision: 0.8954 - specific_output_custom_recall: 0.7514 - val_binary_output_accuracy: 0.9639 - val_binary_output_custom_f1: 0.7912 - val_binary_output_precision_1: 0.9569 - val_binary_output_recall_1: 0.9487 - val_loss: 0.9617 - val_specific_output_categorical_accuracy: 0.7803 - val_specific_output_custom_f1: 0.8033 - val_specific_output_custom_precision: 0.8983 - val_specific_output_custom_recall: 0.7468\n",
            "Epoch 13/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4063s\u001b[0m 13s/step - binary_output_accuracy: 0.9613 - binary_output_custom_f1: 0.7924 - binary_output_precision_1: 0.9381 - binary_output_recall_1: 0.9571 - loss: 0.6201 - specific_output_categorical_accuracy: 0.8282 - specific_output_custom_f1: 0.8376 - specific_output_custom_precision: 0.9282 - specific_output_custom_recall: 0.7810 - val_binary_output_accuracy: 0.9639 - val_binary_output_custom_f1: 0.7758 - val_binary_output_precision_1: 0.9818 - val_binary_output_recall_1: 0.9231 - val_loss: 0.9302 - val_specific_output_categorical_accuracy: 0.7836 - val_specific_output_custom_f1: 0.7955 - val_specific_output_custom_precision: 0.8387 - val_specific_output_custom_recall: 0.7662\n",
            "Epoch 14/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4258s\u001b[0m 14s/step - binary_output_accuracy: 0.9590 - binary_output_custom_f1: 0.8212 - binary_output_precision_1: 0.9546 - binary_output_recall_1: 0.9419 - loss: 0.7694 - specific_output_categorical_accuracy: 0.7948 - specific_output_custom_f1: 0.8065 - specific_output_custom_precision: 0.8910 - specific_output_custom_recall: 0.7540 - val_binary_output_accuracy: 0.9508 - val_binary_output_custom_f1: 0.7671 - val_binary_output_precision_1: 0.9904 - val_binary_output_recall_1: 0.8803 - val_loss: 0.8877 - val_specific_output_categorical_accuracy: 0.8000 - val_specific_output_custom_f1: 0.8177 - val_specific_output_custom_precision: 0.8972 - val_specific_output_custom_recall: 0.7662\n",
            "Epoch 15/15\n",
            "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4626s\u001b[0m 15s/step - binary_output_accuracy: 0.9607 - binary_output_custom_f1: 0.8166 - binary_output_precision_1: 0.9672 - binary_output_recall_1: 0.9336 - loss: 0.7069 - specific_output_categorical_accuracy: 0.8212 - specific_output_custom_f1: 0.8225 - specific_output_custom_precision: 0.9033 - specific_output_custom_recall: 0.7744 - val_binary_output_accuracy: 0.8820 - val_binary_output_custom_f1: 0.7396 - val_binary_output_precision_1: 0.7682 - val_binary_output_recall_1: 0.9915 - val_loss: 1.2304 - val_specific_output_categorical_accuracy: 0.7475 - val_specific_output_custom_f1: 0.7642 - val_specific_output_custom_precision: 0.8885 - val_specific_output_custom_recall: 0.6916\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, MultiHeadAttention, LayerNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define the TransformerBlock class\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = Sequential(\n",
        "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs, training=training)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1, training=training)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# Input layer\n",
        "input_layer = Input(shape=(X_train.shape[1], 1))\n",
        "\n",
        "# Shared layers\n",
        "x = Conv1D(filters=256, kernel_size=2, activation='relu')(input_layer)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Conv1D(filters=128, kernel_size=2, activation='relu')(x)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=256)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(100, activation='relu')(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "# Binary Classification Head (Goodware vs Malicious)\n",
        "binary_output = Dense(1, activation='sigmoid', name='binary_output')(x)\n",
        "\n",
        "# Specific Classification Head\n",
        "specific_output = Dense(12, activation='softmax', name='specific_output')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=[binary_output, specific_output])\n",
        "\n",
        "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def custom_precision(y_true, y_pred):\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "# Custom recall metric for multi-class classification\n",
        "def custom_recall(y_true, y_pred):\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "# Custom F1 score metric for multi-class classification\n",
        "def custom_f1(y_true, y_pred):\n",
        "    precision = custom_precision(y_true, y_pred)\n",
        "    recall = custom_recall(y_true, y_pred)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "    return f1\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'binary_output': 'binary_crossentropy', 'specific_output': 'categorical_crossentropy'},\n",
        "              metrics={'binary_output': ['accuracy', Precision(), Recall(), custom_f1],\n",
        "                  'specific_output': [CategoricalAccuracy(), custom_precision, custom_recall, custom_f1]})\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Mapping original labels to group labels\n",
        "# Assuming original labels are in the range [0, 11]\n",
        "label_to_group = {\n",
        "    0: 0,  # Goodware\n",
        "    1: 1,  # Critroni\n",
        "    2: 1,  # CryptLocker\n",
        "    3: 1,  # CryptoWall\n",
        "    4: 2,  # KOLLAH\n",
        "    5: 2,  # Kovter\n",
        "    6: 2,  # Locker\n",
        "    7: 3,  # MATSNU\n",
        "    8: 3,  # PGPCODER\n",
        "    9: 3,  # Reveton\n",
        "    10: 3,  # TeslaCrypt\n",
        "    11: 3,  # Trojan-Ransom\n",
        "}\n",
        "\n",
        "y_train_group = y_train.map(label_to_group)\n",
        "y_test_group = y_test.map(label_to_group)\n",
        "\n",
        "# One-hot encode the group and specific labels\n",
        "y_train_categorical = to_categorical(y_train, num_classes=12)\n",
        "y_test_categorical = to_categorical(y_test, num_classes=12)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train,\n",
        "                    {'binary_output': y_train_binary, 'specific_output': y_train_categorical},\n",
        "                    epochs=15,\n",
        "                    batch_size=4,\n",
        "                    validation_data=(X_test, {'binary_output': y_test_binary, 'specific_output': y_test_categorical}),\n",
        "                    callbacks=[early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOCcc6if_eqw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Generate predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Binary predictions and metrics\n",
        "binary_predictions = (predictions[0] > 0.5).astype(int)  # Convert probabilities to 0 or 1\n",
        "binary_accuracy = accuracy_score(y_test_binary, binary_predictions)\n",
        "binary_precision = precision_score(y_test_binary, binary_predictions)\n",
        "binary_recall = recall_score(y_test_binary, binary_predictions)\n",
        "binary_f1 = f1_score(y_test_binary, binary_predictions)\n",
        "\n",
        "# Specific predictions and metrics\n",
        "specific_predictions = np.argmax(predictions[1], axis=1)\n",
        "specific_accuracy = accuracy_score(y_test, specific_predictions)\n",
        "specific_precision = precision_score(y_test, specific_predictions, average='macro')\n",
        "specific_recall = recall_score(y_test, specific_predictions, average='macro')\n",
        "specific_f1 = f1_score(y_test, specific_predictions, average='macro')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Binary Classification Metrics:\\n\"\n",
        "      f\"Accuracy: {binary_accuracy:.4f}\\n\"\n",
        "      f\"Precision: {binary_precision:.4f}\\n\"\n",
        "      f\"Recall: {binary_recall:.4f}\\n\"\n",
        "      f\"F1 Score: {binary_f1:.4f}\")\n",
        "\n",
        "print(f\"\\nSpecific Classification Metrics:\\n\"\n",
        "      f\"Accuracy: {specific_accuracy:.4f}\\n\"\n",
        "      f\"Precision: {specific_precision:.4f}\\n\"\n",
        "      f\"Recall: {specific_recall:.4f}\\n\"\n",
        "      f\"F1 Score: {specific_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amobMIbSG508"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, MultiHeadAttention, LayerNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define the TransformerBlock class\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = Sequential(\n",
        "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs, training=training)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1, training=training)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# Input layer\n",
        "input_layer = Input(shape=(X_train.shape[1], 1))\n",
        "\n",
        "# Shared layers\n",
        "x = Conv1D(filters=256, kernel_size=2, activation='relu')(input_layer)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Conv1D(filters=128, kernel_size=2, activation='relu')(x)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = TransformerBlock(embed_dim=128, num_heads=4, ff_dim=256)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(100, activation='relu')(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "# Binary Classification Head (Goodware vs Malicious)\n",
        "binary_output = Dense(1, activation='sigmoid', name='binary_output')(x)\n",
        "\n",
        "# Specific Classification Head\n",
        "specific_output = Dense(12, activation='softmax', name='specific_output')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=[binary_output, specific_output])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'binary_output': 'binary_crossentropy', 'specific_output': 'categorical_crossentropy'},\n",
        "              metrics={'binary_output': 'accuracy', 'specific_output': 'accuracy'})\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Mapping original labels to group labels\n",
        "# Assuming original labels are in the range [0, 11]\n",
        "label_to_group = {\n",
        "    0: 0,  # Goodware\n",
        "    1: 1,  # Critroni\n",
        "    2: 1,  # CryptLocker\n",
        "    3: 1,  # CryptoWall\n",
        "    4: 2,  # KOLLAH\n",
        "    5: 2,  # Kovter\n",
        "    6: 2,  # Locker\n",
        "    7: 3,  # MATSNU\n",
        "    8: 3,  # PGPCODER\n",
        "    9: 3,  # Reveton\n",
        "    10: 3,  # TeslaCrypt\n",
        "    11: 3,  # Trojan-Ransom\n",
        "}\n",
        "\n",
        "y_train_group = y_train.map(label_to_group)\n",
        "y_test_group = y_test.map(label_to_group)\n",
        "\n",
        "# One-hot encode the group and specific labels\n",
        "y_train_categorical = to_categorical(y_train, num_classes=12)\n",
        "y_test_categorical = to_categorical(y_test, num_classes=12)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train,\n",
        "                    {'binary_output': y_train_binary, 'specific_output': y_train_categorical},\n",
        "                    epochs=50,\n",
        "                    batch_size=4,\n",
        "                    validation_data=(X_test, {'binary_output': y_test_binary, 'specific_output': y_test_categorical}),\n",
        "                    callbacks=[early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD6PJgxpG-AY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Generate predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Binary predictions and metrics\n",
        "binary_predictions = (predictions[0] > 0.5).astype(int)  # Convert probabilities to 0 or 1\n",
        "binary_accuracy = accuracy_score(y_test_binary, binary_predictions)\n",
        "binary_precision = precision_score(y_test_binary, binary_predictions)\n",
        "binary_recall = recall_score(y_test_binary, binary_predictions)\n",
        "binary_f1 = f1_score(y_test_binary, binary_predictions)\n",
        "\n",
        "# Specific predictions and metrics\n",
        "specific_predictions = np.argmax(predictions[1], axis=1)\n",
        "specific_accuracy = accuracy_score(y_test, specific_predictions)\n",
        "specific_precision = precision_score(y_test, specific_predictions, average='macro')\n",
        "specific_recall = recall_score(y_test, specific_predictions, average='macro')\n",
        "specific_f1 = f1_score(y_test, specific_predictions, average='macro')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Binary Classification Metrics:\\n\"\n",
        "      f\"Accuracy: {binary_accuracy:.4f}\\n\"\n",
        "      f\"Precision: {binary_precision:.4f}\\n\"\n",
        "      f\"Recall: {binary_recall:.4f}\\n\"\n",
        "      f\"F1 Score: {binary_f1:.4f}\")\n",
        "\n",
        "print(f\"\\nSpecific Classification Metrics:\\n\"\n",
        "      f\"Accuracy: {specific_accuracy:.4f}\\n\"\n",
        "      f\"Precision: {specific_precision:.4f}\\n\"\n",
        "      f\"Recall: {specific_recall:.4f}\\n\"\n",
        "      f\"F1 Score: {specific_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUCaTL_x93Ht"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the history for each output\n",
        "binary_loss = history.history['binary_output_loss']\n",
        "val_binary_loss = history.history['val_binary_output_loss']\n",
        "specific_loss = history.history['specific_output_loss']\n",
        "val_specific_loss = history.history['val_specific_output_loss']\n",
        "\n",
        "binary_acc = history.history['binary_output_accuracy']\n",
        "val_binary_acc = history.history['val_binary_output_accuracy']\n",
        "specific_acc = history.history['specific_output_accuracy']\n",
        "val_specific_acc = history.history['val_specific_output_accuracy']\n",
        "\n",
        "# Plot loss\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(binary_loss, linestyle='--', label='Binary Output Loss')\n",
        "plt.plot(val_binary_loss, label='Val Binary Output Loss')\n",
        "plt.plot(specific_loss, linestyle='--', label='Specific Output Loss')\n",
        "plt.plot(val_specific_loss, label='Val Specific Output Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(binary_acc, linestyle='--', label='Binary Output Accuracy')\n",
        "plt.plot(val_binary_acc, label='Val Binary Output Accuracy')\n",
        "plt.plot(specific_acc, linestyle='--', label='Specific Output Accuracy')\n",
        "plt.plot(val_specific_acc, label='Val Specific Output Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tcex7Sk9rCtm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Binary classification confusion matrix\n",
        "binary_preds = np.round(predictions[0]).astype(int)\n",
        "binary_cm = confusion_matrix(y_test_binary, binary_preds)\n",
        "# Specific classification confusion matrix\n",
        "specific_preds = np.argmax(predictions[2], axis=1)\n",
        "specific_cm = confusion_matrix(y_test, specific_preds)\n",
        "\n",
        "# Plot confusion matrices\n",
        "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "# Plot Binary classification confusion matrix\n",
        "plot_confusion_matrix(binary_cm, classes=['Goodware', 'Malicious'], title='Binary Classification Confusion Matrix')\n",
        "\n",
        "\n",
        "# Plot Specific classification confusion matrix\n",
        "specific_labels = ['Goodware', 'Critroni', 'CryptLocker', 'CryptoWall', 'KOLLAH', 'Kovter', 'Locker', 'MATSNU', 'PGPCODER', 'Reveton', 'TeslaCrypt', 'Trojan-Ransom']\n",
        "plot_confusion_matrix(specific_cm, classes=specific_labels, title='Specific Classification Confusion Matrix')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58n_8tORa5bi"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "# Plot the model\n",
        "plot_model(model, to_file='cnt_model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Display the model\n",
        "img = mpimg.imread('cnt_model.png')\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}